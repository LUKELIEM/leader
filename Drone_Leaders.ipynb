{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DroneLeader Architecture\n",
    "\n",
    "We envision a multi-agent organization whereby:\n",
    "\n",
    "* A Strategist directs multiple Teams through Tasks/Objectives.\n",
    "\n",
    "* Each Team is made up of agents of different types (drones and crawlers) and roles (leaders and followers).\n",
    "\n",
    "* A Team uses its Culture to shape its agents' behaviors by doling out behavorial rewards during training. It uses its Mission to help its agents learn abilities to accomplish individual or group objectives by doling out mission rewards during training.\n",
    "\n",
    "* In this way, a Strategist that is optimized for strategic decision making can analyze the games space and direct multiple Teams to accomplish more complex and strategic tasks that require more than behavioral skills.\n",
    "\n",
    "However, we are not able to reliably train droneleaders with simple 2-layer FC-Softmax policies to learn how to minimize the delta between the drone's coordinate and the target coordinate of max favoribility given by the Strategist.\n",
    "\n",
    "We will implement several different drone leaders to find out which is the most reliable:\n",
    "\n",
    "- DroneLeader_FC32: a 2 layer FC-Softmax (32 hidden units) policy with the deltas (between drone and target coordinates) as input\n",
    "- DroneLeader_FC64: a 2 layer FC-Softmax (64 hidden units) policy with the deltas (between drone and target coordinates) as input\n",
    "- DroneLeader_CNN1: a CNN policy with a 1-frame game space of drone and goal locations as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.4\n",
      "Pytorch version: 0.4.1.post2\n",
      "OpenAI Gym version: 0.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import platform\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# This is the Crossing game environment\n",
    "from xteams_env import CrossingEnv\n",
    "from xteams_model import *\n",
    "from interface import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Pytorch version: {}\".format(torch.__version__))\n",
    "print(\"OpenAI Gym version: {}\".format(gym.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategist Class\n",
    "\n",
    "(Wikipedia) A strategist is responsible for the formulation and implementation of a strategy. Strategy generally involves setting goals, determining actions to achieve the goals, and mobilizing resources to execute the actions. It describes how the ends (goals) will be achieved by the means (resources).\n",
    "\n",
    "An agent belonging to the Strategist class performs the following:\n",
    "\n",
    "(1) It accepts and abdicates responsibilities for directing teams of agents\n",
    "\n",
    "(2) It receives game space and metrics from the Environment\n",
    "\n",
    "(3) It analyzes the game space and metrics to arrive at a \"strategic position\" for its teams. e.g. a topological map and/or a set of game stats\n",
    "\n",
    "(4) Based on the strategic position, it decides on a set of goals that need to be accomplished\n",
    "\n",
    "(5) It surveys its teams of agents and their location in the games space\n",
    "\n",
    "(6) For each goal, it picks the best team and assign it the goal\n",
    "\n",
    "(7) If necessary, it reorganize the teams and the agents\n",
    "\n",
    "(8) It measures the effectiveness of the teams in accomplishing the assigned goals, and whether the \"strategic position\" has improved for its teams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Team directed by Strategist\n",
    "\n",
    "For now, a strategist can only direct 1 team with a drone agent, which acts as the \"eye\" for the strategist. The strategist access the game space through the complete obs space of the drone agent.\n",
    "\n",
    "The code below run training on 2 teams of 5 Agents each. Both team Viking and Franks have Pacifist cultures so they are unagressive (do not fire their lasers). The Vikings have a drone leader and a strategist. The Franks do not.\n",
    "\n",
    "Our strategist is able to take in the game space provided by its eye and output a goal in the form of a coordinate. \n",
    "\n",
    "The Team class must now take this goal (\"move the team to this coordinate\") and generate the mission reward such that its leader agent learns to move to that coordinate, thus taking many of its followers along in its target zone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DroneLeader_FC32 and DroneLeader_FC64\n",
    "\n",
    "The DroneLeader_FC32 is a 2-layer fully-connected NN with 32 hidden units that accepts the normalized deltas between the droneleader's coordinate vs the target coordinate of max favorability as input to output an action.\n",
    "\n",
    "The DroneLeader_FC64 is a 2-layer fully-connected NN with 64 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DroneLeader_FC32(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=32, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "  )\n",
      "  (action_head): Linear(in_features=32, out_features=12, bias=True)\n",
      ")\n",
      "tensor([[0.0782, 0.1387, 0.0621, 0.0547, 0.0694, 0.0692, 0.1014, 0.0987, 0.1282,\n",
      "         0.0692, 0.0596, 0.0705]], grad_fn=<SoftmaxBackward>)\n",
      "DroneLeader_FC64(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "  )\n",
      "  (action_head): Linear(in_features=64, out_features=12, bias=True)\n",
      ")\n",
      "tensor([[0.0741, 0.0707, 0.1195, 0.0622, 0.0982, 0.0790, 0.1015, 0.0696, 0.0872,\n",
      "         0.1058, 0.0614, 0.0707]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "num_drone_actions = 12\n",
    "num_goal_params = 2\n",
    "\n",
    "drone_leader = DroneLeader_FC32(num_goal_params, num_drone_actions, 0)\n",
    "print (drone_leader)\n",
    "\n",
    "batch_size = 1\n",
    "x = torch.randn(batch_size, 2)\n",
    "output = drone_leader(x)\n",
    "print(output)\n",
    "\n",
    "drone_leader = DroneLeader_FC64(num_goal_params, num_drone_actions, 0)\n",
    "print (drone_leader)\n",
    "\n",
    "batch_size = 1\n",
    "x = torch.randn(batch_size, 2)\n",
    "output = drone_leader(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - DroneLeader_FC32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner agent 0\n",
      "Load Drone Leader.\n",
      "..........\n",
      "Episode 10 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:61\tRunning mean: 42.17\n",
      "Max Norms =  ['22.96']\n",
      "..........\n",
      "Episode 20 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:58\tRunning mean: 43.92\n",
      "Max Norms =  ['20.21']\n",
      "..........\n",
      "Episode 30 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:58\tRunning mean: 45.63\n",
      "Max Norms =  ['14.24']\n",
      "..........\n",
      "Episode 40 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:56\tRunning mean: 47.09\n",
      "Max Norms =  ['20.40']\n",
      "..........\n",
      "Episode 50 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:67\tRunning mean: 48.01\n",
      "Max Norms =  ['19.13']\n",
      "..........\n",
      "Episode 60 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:60\tRunning mean: 48.78\n",
      "Max Norms =  ['19.69']\n",
      "..........\n",
      "Episode 70 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:30\tRunning mean: 48.42\n",
      "Max Norms =  ['16.31']\n",
      "..........\n",
      "Episode 80 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:49\tRunning mean: 48.49\n",
      "Max Norms =  ['20.55']\n",
      "..........\n",
      "Episode 90 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:49\tRunning mean: 48.44\n",
      "Max Norms =  ['16.54']\n",
      "..........\n",
      "Episode 100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:49\tRunning mean: 47.33\n",
      "Max Norms =  ['15.90']\n",
      "..........\n",
      "Episode 110 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:22\tRunning mean: 46.22\n",
      "Max Norms =  ['13.57']\n",
      "..........\n",
      "Episode 120 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:23\tRunning mean: 44.0\n",
      "Max Norms =  ['14.94']\n",
      "..........\n",
      "Episode 130 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:17\tRunning mean: 41.38\n",
      "Max Norms =  ['22.21']\n",
      "..........\n",
      "Episode 140 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:14\tRunning mean: 38.27\n",
      "Max Norms =  ['19.95']\n",
      "..........\n",
      "Episode 150 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 35.33\n",
      "Max Norms =  ['21.84']\n",
      "..........\n",
      "Episode 160 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 32.78\n",
      "Max Norms =  ['34.38']\n",
      "..........\n",
      "Episode 170 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 30.32\n",
      "Max Norms =  ['22.90']\n",
      "..........\n",
      "Episode 180 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 28.08\n",
      "Max Norms =  ['11.75']\n",
      "..........\n",
      "Episode 190 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 26.16\n",
      "Max Norms =  ['20.13']\n",
      "..........\n",
      "Episode 200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 24.33\n",
      "Max Norms =  ['16.79']\n",
      "..........\n",
      "Episode 210 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 22.61\n",
      "Max Norms =  ['9.39']\n",
      "..........\n",
      "Episode 220 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 21.14\n",
      "Max Norms =  ['9.94']\n",
      "..........\n",
      "Episode 230 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 19.8\n",
      "Max Norms =  ['10.29']\n",
      "..........\n",
      "Episode 240 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 18.59\n",
      "Max Norms =  ['12.71']\n",
      "..........\n",
      "Episode 250 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 17.44\n",
      "Max Norms =  ['23.37']\n",
      "..........\n",
      "Episode 260 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 16.46\n",
      "Max Norms =  ['23.06']\n",
      "..........\n",
      "Episode 270 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 15.5\n",
      "Max Norms =  ['28.01']\n",
      "..........\n",
      "Episode 280 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 14.67\n",
      "Max Norms =  ['13.69']\n",
      "..........\n",
      "Episode 290 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 13.96\n",
      "Max Norms =  ['13.13']\n",
      "..........\n",
      "Episode 300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 13.36\n",
      "Max Norms =  ['25.54']\n",
      "..........\n",
      "Episode 310 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 12.82\n",
      "Max Norms =  ['17.24']\n",
      "..........\n",
      "Episode 320 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 12.32\n",
      "Max Norms =  ['9.92']\n",
      "..........\n",
      "Episode 330 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 11.86\n",
      "Max Norms =  ['22.33']\n",
      "..........\n",
      "Episode 340 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 11.4\n",
      "Max Norms =  ['40.87']\n",
      "..........\n",
      "Episode 350 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:18\tRunning mean: 11.3\n",
      "Max Norms =  ['24.34']\n",
      "..........\n",
      "Episode 360 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 11.14\n",
      "Max Norms =  ['29.49']\n",
      "..........\n",
      "Episode 370 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 10.69\n",
      "Max Norms =  ['28.57']\n",
      "..........\n",
      "Episode 380 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 10.23\n",
      "Max Norms =  ['14.88']\n",
      "..........\n",
      "Episode 390 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 9.895\n",
      "Max Norms =  ['16.33']\n",
      "..........\n",
      "Episode 400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 9.569\n",
      "Max Norms =  ['24.48']\n",
      "..........\n",
      "Episode 410 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 9.303\n",
      "Max Norms =  ['18.04']\n",
      "..........\n",
      "Episode 420 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 9.083\n",
      "Max Norms =  ['14.36']\n",
      "..........\n",
      "Episode 430 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 8.845\n",
      "Max Norms =  ['27.73']\n",
      "..........\n",
      "Episode 440 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 8.498\n",
      "Max Norms =  ['11.28']\n",
      "..........\n",
      "Episode 450 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 8.336\n",
      "Max Norms =  ['19.51']\n",
      "..........\n",
      "Episode 460 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 8.078\n",
      "Max Norms =  ['8.36']\n",
      "..........\n",
      "Episode 470 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 7.897\n",
      "Max Norms =  ['11.58']\n",
      "..........\n",
      "Episode 480 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.764\n",
      "Max Norms =  ['20.07']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 490 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.539\n",
      "Max Norms =  ['14.38']\n",
      "..........\n",
      "Episode 500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.392\n",
      "Max Norms =  ['5.49']\n",
      "..........\n",
      "Episode 510 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 7.124\n",
      "Max Norms =  ['24.69']\n",
      "..........\n",
      "Episode 520 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.836\n",
      "Max Norms =  ['6.19']\n",
      "..........\n",
      "Episode 530 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.891\n",
      "Max Norms =  ['15.60']\n",
      "..........\n",
      "Episode 540 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.929\n",
      "Max Norms =  ['8.35']\n",
      "..........\n",
      "Episode 550 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.984\n",
      "Max Norms =  ['10.91']\n",
      "..........\n",
      "Episode 560 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.08\n",
      "Max Norms =  ['12.12']\n",
      "..........\n",
      "Episode 570 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.129\n",
      "Max Norms =  ['22.60']\n",
      "..........\n",
      "Episode 580 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.137\n",
      "Max Norms =  ['47.37']\n",
      "..........\n",
      "Episode 590 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.201\n",
      "Max Norms =  ['26.74']\n",
      "..........\n",
      "Episode 600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.188\n",
      "Max Norms =  ['23.47']\n",
      "..........\n",
      "Episode 610 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.22\n",
      "Max Norms =  ['21.37']\n",
      "..........\n",
      "Episode 620 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.286\n",
      "Max Norms =  ['24.09']\n",
      "..........\n",
      "Episode 630 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.266\n",
      "Max Norms =  ['50.01']\n",
      "..........\n",
      "Episode 640 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.193\n",
      "Max Norms =  ['34.89']\n",
      "..........\n",
      "Episode 650 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.106\n",
      "Max Norms =  ['26.59']\n",
      "..........\n",
      "Episode 660 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.02\n",
      "Max Norms =  ['15.80']\n",
      "..........\n",
      "Episode 670 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.978\n",
      "Max Norms =  ['68.68']\n",
      "..........\n",
      "Episode 680 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.961\n",
      "Max Norms =  ['27.14']\n",
      "..........\n",
      "Episode 690 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.917\n",
      "Max Norms =  ['30.06']\n",
      "..........\n",
      "Episode 700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.885\n",
      "Max Norms =  ['59.75']\n",
      "..........\n",
      "Episode 710 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.809\n",
      "Max Norms =  ['27.51']\n",
      "..........\n",
      "Episode 720 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.848\n",
      "Max Norms =  ['27.26']\n",
      "..........\n",
      "Episode 730 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.932\n",
      "Max Norms =  ['10.71']\n",
      "..........\n",
      "Episode 740 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.053\n",
      "Max Norms =  ['64.48']\n",
      "..........\n",
      "Episode 750 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.24\n",
      "Max Norms =  ['45.98']\n",
      "..........\n",
      "Episode 760 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.408\n",
      "Max Norms =  ['43.39']\n",
      "..........\n",
      "Episode 770 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.56\n",
      "Max Norms =  ['24.98']\n",
      "..........\n",
      "Episode 780 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.67\n",
      "Max Norms =  ['36.14']\n",
      "..........\n",
      "Episode 790 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.709\n",
      "Max Norms =  ['17.43']\n",
      "..........\n",
      "Episode 800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.564\n",
      "Max Norms =  ['41.43']\n",
      "..........\n",
      "Episode 810 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.473\n",
      "Max Norms =  ['31.47']\n",
      "..........\n",
      "Episode 820 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.411\n",
      "Max Norms =  ['8.41']\n",
      "..........\n",
      "Episode 830 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.325\n",
      "Max Norms =  ['18.41']\n",
      "..........\n",
      "Episode 840 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.274\n",
      "Max Norms =  ['18.39']\n",
      "..........\n",
      "Episode 850 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.171\n",
      "Max Norms =  ['9.49']\n",
      "..........\n",
      "Episode 860 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.031\n",
      "Max Norms =  ['27.57']\n",
      "..........\n",
      "Episode 870 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.914\n",
      "Max Norms =  ['12.98']\n",
      "..........\n",
      "Episode 880 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.924\n",
      "Max Norms =  ['6.56']\n",
      "..........\n",
      "Episode 890 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.009\n",
      "Max Norms =  ['15.98']\n",
      "..........\n",
      "Episode 900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.142\n",
      "Max Norms =  ['11.98']\n",
      "..........\n",
      "Episode 910 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.311\n",
      "Max Norms =  ['30.83']\n",
      "..........\n",
      "Episode 920 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.472\n",
      "Max Norms =  ['26.60']\n",
      "..........\n",
      "Episode 930 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.608\n",
      "Max Norms =  ['12.44']\n",
      "..........\n",
      "Episode 940 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.741\n",
      "Max Norms =  ['8.79']\n",
      "..........\n",
      "Episode 950 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.813\n",
      "Max Norms =  ['21.27']\n",
      "..........\n",
      "Episode 960 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.805\n",
      "Max Norms =  ['33.70']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 970 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.862\n",
      "Max Norms =  ['41.46']\n",
      "..........\n",
      "Episode 980 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.883\n",
      "Max Norms =  ['22.75']\n",
      "..........\n",
      "Episode 990 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.915\n",
      "Max Norms =  ['13.49']\n",
      "..........\n",
      "Episode 1000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.931\n",
      "Max Norms =  ['30.59']\n",
      "..........\n",
      "Episode 1010 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.94\n",
      "Max Norms =  ['16.38']\n",
      "..........\n",
      "Episode 1020 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.956\n",
      "Max Norms =  ['19.56']\n",
      "..........\n",
      "Episode 1030 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.026\n",
      "Max Norms =  ['16.85']\n",
      "..........\n",
      "Episode 1040 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.12\n",
      "Max Norms =  ['8.83']\n",
      "..........\n",
      "Episode 1050 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.165\n",
      "Max Norms =  ['15.10']\n",
      "..........\n",
      "Episode 1060 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.226\n",
      "Max Norms =  ['9.98']\n",
      "..........\n",
      "Episode 1070 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.29\n",
      "Max Norms =  ['20.88']\n",
      "..........\n",
      "Episode 1080 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 8.215\n",
      "Max Norms =  ['26.67']\n",
      "..........\n",
      "Episode 1090 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 8.107\n",
      "Max Norms =  ['16.42']\n",
      "..........\n",
      "Episode 1100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 8.011\n",
      "Max Norms =  ['18.46']\n",
      "..........\n",
      "Episode 1110 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.857\n",
      "Max Norms =  ['15.65']\n",
      "..........\n",
      "Episode 1120 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.825\n",
      "Max Norms =  ['13.25']\n",
      "..........\n",
      "Episode 1130 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.785\n",
      "Max Norms =  ['10.50']\n",
      "..........\n",
      "Episode 1140 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.774\n",
      "Max Norms =  ['7.78']\n",
      "..........\n",
      "Episode 1150 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.603\n",
      "Max Norms =  ['11.50']\n",
      "..........\n",
      "Episode 1160 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.572\n",
      "Max Norms =  ['11.40']\n",
      "..........\n",
      "Episode 1170 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.517\n",
      "Max Norms =  ['36.88']\n",
      "..........\n",
      "Episode 1180 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.486\n",
      "Max Norms =  ['26.78']\n",
      "..........\n",
      "Episode 1190 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.363\n",
      "Max Norms =  ['20.02']\n",
      "..........\n",
      "Episode 1200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.251\n",
      "Max Norms =  ['21.09']\n",
      "..........\n",
      "Episode 1210 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.122\n",
      "Max Norms =  ['60.03']\n",
      "..........\n",
      "Episode 1220 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.072\n",
      "Max Norms =  ['24.25']\n",
      "..........\n",
      "Episode 1230 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 6.795\n",
      "Max Norms =  ['13.26']\n",
      "..........\n",
      "Episode 1240 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.45\n",
      "Max Norms =  ['8.42']\n",
      "..........\n",
      "Episode 1250 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 6.178\n",
      "Max Norms =  ['24.39']\n",
      "..........\n",
      "Episode 1260 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.134\n",
      "Max Norms =  ['9.58']\n",
      "..........\n",
      "Episode 1270 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.102\n",
      "Max Norms =  ['3.96']\n",
      "..........\n",
      "Episode 1280 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.018\n",
      "Max Norms =  ['10.59']\n",
      "..........\n",
      "Episode 1290 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 5.987\n",
      "Max Norms =  ['10.87']\n",
      "..........\n",
      "Episode 1300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.806\n",
      "Max Norms =  ['10.79']\n",
      "..........\n",
      "Episode 1310 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.827\n",
      "Max Norms =  ['10.41']\n",
      "..........\n",
      "Episode 1320 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.721\n",
      "Max Norms =  ['7.78']\n",
      "..........\n",
      "Episode 1330 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.741\n",
      "Max Norms =  ['10.07']\n",
      "..........\n",
      "Episode 1340 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.842\n",
      "Max Norms =  ['43.97']\n",
      "..........\n",
      "Episode 1350 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.914\n",
      "Max Norms =  ['16.15']\n",
      "..........\n",
      "Episode 1360 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.018\n",
      "Max Norms =  ['5.45']\n",
      "..........\n",
      "Episode 1370 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.093\n",
      "Max Norms =  ['14.51']\n",
      "..........\n",
      "Episode 1380 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.074\n",
      "Max Norms =  ['15.98']\n",
      "..........\n",
      "Episode 1390 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.057\n",
      "Max Norms =  ['21.16']\n",
      "..........\n",
      "Episode 1400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.013\n",
      "Max Norms =  ['15.69']\n",
      "..........\n",
      "Episode 1410 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.118\n",
      "Max Norms =  ['34.08']\n",
      "..........\n",
      "Episode 1420 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.173\n",
      "Max Norms =  ['7.28']\n",
      "..........\n",
      "Episode 1430 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.204\n",
      "Max Norms =  ['11.94']\n",
      "..........\n",
      "Episode 1440 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.173\n",
      "Max Norms =  ['25.23']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 1450 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.166\n",
      "Max Norms =  ['20.89']\n",
      "..........\n",
      "Episode 1460 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.169\n",
      "Max Norms =  ['24.09']\n",
      "..........\n",
      "Episode 1470 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.171\n",
      "Max Norms =  ['7.93']\n",
      "..........\n",
      "Episode 1480 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.164\n",
      "Max Norms =  ['9.72']\n",
      "..........\n",
      "Episode 1490 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.205\n",
      "Max Norms =  ['23.50']\n",
      "..........\n",
      "Episode 1500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.165\n",
      "Max Norms =  ['43.93']\n",
      "..........\n",
      "Episode 1510 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 6.081\n",
      "Max Norms =  ['21.40']\n",
      "..........\n",
      "Episode 1520 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.043\n",
      "Max Norms =  ['23.17']\n",
      "..........\n",
      "Episode 1530 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.048\n",
      "Max Norms =  ['9.73']\n",
      "..........\n",
      "Episode 1540 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.094\n",
      "Max Norms =  ['31.55']\n",
      "..........\n",
      "Episode 1550 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.238\n",
      "Max Norms =  ['13.33']\n",
      "..........\n",
      "Episode 1560 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.376\n",
      "Max Norms =  ['11.63']\n",
      "..........\n",
      "Episode 1570 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 6.261\n",
      "Max Norms =  ['23.75']\n",
      "..........\n",
      "Episode 1580 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.219\n",
      "Max Norms =  ['19.32']\n",
      "..........\n",
      "Episode 1590 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.16\n",
      "Max Norms =  ['27.26']\n",
      "..........\n",
      "Episode 1600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 6.0\n",
      "Max Norms =  ['10.69']\n",
      "..........\n",
      "Episode 1610 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 5.691\n",
      "Max Norms =  ['9.83']\n",
      "..........\n",
      "Episode 1620 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.435\n",
      "Max Norms =  ['17.25']\n",
      "..........\n",
      "Episode 1630 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 5.304\n",
      "Max Norms =  ['8.46']\n",
      "..........\n",
      "Episode 1640 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 5.151\n",
      "Max Norms =  ['22.85']\n",
      "..........\n",
      "Episode 1650 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 5.154\n",
      "Max Norms =  ['24.75']\n",
      "..........\n",
      "Episode 1660 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 4.995\n",
      "Max Norms =  ['9.19']\n",
      "..........\n",
      "Episode 1670 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 4.919\n",
      "Max Norms =  ['21.36']\n",
      "..........\n",
      "Episode 1680 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 4.968\n",
      "Max Norms =  ['17.97']\n",
      "..........\n",
      "Episode 1690 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 5.067\n",
      "Max Norms =  ['26.30']\n",
      "..........\n",
      "Episode 1700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.215\n",
      "Max Norms =  ['12.42']\n",
      "..........\n",
      "Episode 1710 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.339\n",
      "Max Norms =  ['17.45']\n",
      "..........\n",
      "Episode 1720 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.526\n",
      "Max Norms =  ['26.98']\n",
      "..........\n",
      "Episode 1730 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.666\n",
      "Max Norms =  ['11.69']\n",
      "..........\n",
      "Episode 1740 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 5.859\n",
      "Max Norms =  ['45.31']\n",
      "..........\n",
      "Episode 1750 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.995\n",
      "Max Norms =  ['9.33']\n",
      "..........\n",
      "Episode 1760 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.024\n",
      "Max Norms =  ['18.12']\n",
      "..........\n",
      "Episode 1770 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.118\n",
      "Max Norms =  ['11.03']\n",
      "..........\n",
      "Episode 1780 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.28\n",
      "Max Norms =  ['12.59']\n",
      "..........\n",
      "Episode 1790 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.271\n",
      "Max Norms =  ['16.70']\n",
      "..........\n",
      "Episode 1800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.351\n",
      "Max Norms =  ['17.21']\n",
      "..........\n",
      "Episode 1810 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.45\n",
      "Max Norms =  ['55.44']\n",
      "..........\n",
      "Episode 1820 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.657\n",
      "Max Norms =  ['108.93']\n",
      "..........\n",
      "Episode 1830 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.785\n",
      "Max Norms =  ['8.97']\n",
      "..........\n",
      "Episode 1840 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.728\n",
      "Max Norms =  ['2.48']\n",
      "..........\n",
      "Episode 1850 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.697\n",
      "Max Norms =  ['6.15']\n",
      "..........\n",
      "Episode 1860 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.632\n",
      "Max Norms =  ['6.82']\n",
      "..........\n",
      "Episode 1870 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.65\n",
      "Max Norms =  ['0.89']\n",
      "..........\n",
      "Episode 1880 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.633\n",
      "Max Norms =  ['10.16']\n",
      "..........\n",
      "Episode 1890 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.63\n",
      "Max Norms =  ['9.53']\n",
      "..........\n",
      "Episode 1900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.772\n",
      "Max Norms =  ['14.81']\n",
      "..........\n",
      "Episode 1910 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.858\n",
      "Max Norms =  ['5.42']\n",
      "..........\n",
      "Episode 1920 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.842\n",
      "Max Norms =  ['13.52']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 1930 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.964\n",
      "Max Norms =  ['22.66']\n",
      "..........\n",
      "Episode 1940 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.159\n",
      "Max Norms =  ['14.72']\n",
      "..........\n",
      "Episode 1950 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.335\n",
      "Max Norms =  ['13.56']\n",
      "..........\n",
      "Episode 1960 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.474\n",
      "Max Norms =  ['10.36']\n",
      "..........\n",
      "Episode 1970 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.417\n",
      "Max Norms =  ['6.01']\n",
      "..........\n",
      "Episode 1980 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.262\n",
      "Max Norms =  ['12.99']\n",
      "..........\n",
      "Episode 1990 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.123\n",
      "Max Norms =  ['10.65']\n",
      "..........\n",
      "Episode 2000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.006\n",
      "Max Norms =  ['11.40']\n",
      "\n",
      "Training time: 181.19 sec\n",
      "Learner agent 0\n",
      "Load Drone Leader.\n",
      "..........\n",
      "Episode 10 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:34\tRunning mean: 58.62\n",
      "Max Norms =  ['12.32']\n",
      "..........\n",
      "Episode 20 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:50\tRunning mean: 56.88\n",
      "Max Norms =  ['21.39']\n",
      "..........\n",
      "Episode 30 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:56\tRunning mean: 56.21\n",
      "Max Norms =  ['14.33']\n",
      "..........\n",
      "Episode 40 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:48\tRunning mean: 55.47\n",
      "Max Norms =  ['17.94']\n",
      "..........\n",
      "Episode 50 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:45\tRunning mean: 54.8\n",
      "Max Norms =  ['15.60']\n",
      "..........\n",
      "Episode 60 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:48\tRunning mean: 53.95\n",
      "Max Norms =  ['17.05']\n",
      "..........\n",
      "Episode 70 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:33\tRunning mean: 52.66\n",
      "Max Norms =  ['12.28']\n",
      "..........\n",
      "Episode 80 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:42\tRunning mean: 50.99\n",
      "Max Norms =  ['15.27']\n",
      "..........\n",
      "Episode 90 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:42\tRunning mean: 50.24\n",
      "Max Norms =  ['17.14']\n",
      "..........\n",
      "Episode 100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:43\tRunning mean: 49.24\n",
      "Max Norms =  ['15.00']\n",
      "..........\n",
      "Episode 110 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:34\tRunning mean: 48.16\n",
      "Max Norms =  ['14.48']\n",
      "..........\n",
      "Episode 120 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:42\tRunning mean: 47.29\n",
      "Max Norms =  ['17.79']\n",
      "..........\n",
      "Episode 130 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:27\tRunning mean: 46.07\n",
      "Max Norms =  ['19.00']\n",
      "..........\n",
      "Episode 140 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:35\tRunning mean: 44.85\n",
      "Max Norms =  ['25.41']\n",
      "..........\n",
      "Episode 150 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:35\tRunning mean: 43.58\n",
      "Max Norms =  ['9.83']\n",
      "..........\n",
      "Episode 160 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:37\tRunning mean: 42.04\n",
      "Max Norms =  ['20.53']\n",
      "..........\n",
      "Episode 170 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:16\tRunning mean: 39.12\n",
      "Max Norms =  ['19.12']\n",
      "..........\n",
      "Episode 180 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:16\tRunning mean: 36.35\n",
      "Max Norms =  ['26.08']\n",
      "..........\n",
      "Episode 190 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 33.95\n",
      "Max Norms =  ['20.39']\n",
      "..........\n",
      "Episode 200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:12\tRunning mean: 31.41\n",
      "Max Norms =  ['21.91']\n",
      "..........\n",
      "Episode 210 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 29.15\n",
      "Max Norms =  ['19.23']\n",
      "..........\n",
      "Episode 220 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 27.09\n",
      "Max Norms =  ['22.40']\n",
      "..........\n",
      "Episode 230 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 25.15\n",
      "Max Norms =  ['24.11']\n",
      "..........\n",
      "Episode 240 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 23.48\n",
      "Max Norms =  ['15.25']\n",
      "..........\n",
      "Episode 250 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 21.97\n",
      "Max Norms =  ['27.46']\n",
      "..........\n",
      "Episode 260 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 20.63\n",
      "Max Norms =  ['20.27']\n",
      "..........\n",
      "Episode 270 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 19.58\n",
      "Max Norms =  ['17.78']\n",
      "..........\n",
      "Episode 280 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 18.38\n",
      "Max Norms =  ['20.37']\n",
      "..........\n",
      "Episode 290 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 17.36\n",
      "Max Norms =  ['15.97']\n",
      "..........\n",
      "Episode 300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 16.38\n",
      "Max Norms =  ['20.30']\n",
      "..........\n",
      "Episode 310 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 15.61\n",
      "Max Norms =  ['15.55']\n",
      "..........\n",
      "Episode 320 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 14.77\n",
      "Max Norms =  ['22.99']\n",
      "..........\n",
      "Episode 330 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 14.02\n",
      "Max Norms =  ['13.94']\n",
      "..........\n",
      "Episode 340 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 13.4\n",
      "Max Norms =  ['14.68']\n",
      "..........\n",
      "Episode 350 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:13\tRunning mean: 12.81\n",
      "Max Norms =  ['12.49']\n",
      "..........\n",
      "Episode 360 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 12.3\n",
      "Max Norms =  ['28.02']\n",
      "..........\n",
      "Episode 370 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 11.95\n",
      "Max Norms =  ['17.55']\n",
      "..........\n",
      "Episode 380 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 11.6\n",
      "Max Norms =  ['17.57']\n",
      "..........\n",
      "Episode 390 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 11.28\n",
      "Max Norms =  ['26.70']\n",
      "..........\n",
      "Episode 400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 10.92\n",
      "Max Norms =  ['16.62']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 410 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:10\tRunning mean: 10.72\n",
      "Max Norms =  ['23.29']\n",
      "..........\n",
      "Episode 420 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 10.33\n",
      "Max Norms =  ['14.16']\n",
      "..........\n",
      "Episode 430 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 9.948\n",
      "Max Norms =  ['19.08']\n",
      "..........\n",
      "Episode 440 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 9.696\n",
      "Max Norms =  ['19.65']\n",
      "..........\n",
      "Episode 450 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 9.44\n",
      "Max Norms =  ['17.87']\n",
      "..........\n",
      "Episode 460 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 9.112\n",
      "Max Norms =  ['15.56']\n",
      "..........\n",
      "Episode 470 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 8.881\n",
      "Max Norms =  ['20.31']\n",
      "..........\n",
      "Episode 480 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 8.751\n",
      "Max Norms =  ['22.48']\n",
      "..........\n",
      "Episode 490 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 8.642\n",
      "Max Norms =  ['17.49']\n",
      "..........\n",
      "Episode 500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.534\n",
      "Max Norms =  ['21.66']\n",
      "..........\n",
      "Episode 510 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 8.387\n",
      "Max Norms =  ['20.17']\n",
      "..........\n",
      "Episode 520 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.342\n",
      "Max Norms =  ['15.23']\n",
      "..........\n",
      "Episode 530 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.291\n",
      "Max Norms =  ['32.59']\n",
      "..........\n",
      "Episode 540 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.227\n",
      "Max Norms =  ['17.28']\n",
      "..........\n",
      "Episode 550 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 8.051\n",
      "Max Norms =  ['17.14']\n",
      "..........\n",
      "Episode 560 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.912\n",
      "Max Norms =  ['14.36']\n",
      "..........\n",
      "Episode 570 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.866\n",
      "Max Norms =  ['32.78']\n",
      "..........\n",
      "Episode 580 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.736\n",
      "Max Norms =  ['18.95']\n",
      "..........\n",
      "Episode 590 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.571\n",
      "Max Norms =  ['23.57']\n",
      "..........\n",
      "Episode 600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.401\n",
      "Max Norms =  ['15.59']\n",
      "..........\n",
      "Episode 610 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.326\n",
      "Max Norms =  ['25.72']\n",
      "..........\n",
      "Episode 620 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.228\n",
      "Max Norms =  ['13.16']\n",
      "..........\n",
      "Episode 630 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:10\tRunning mean: 7.132\n",
      "Max Norms =  ['17.38']\n",
      "..........\n",
      "Episode 640 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.08\n",
      "Max Norms =  ['16.41']\n",
      "..........\n",
      "Episode 650 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.099\n",
      "Max Norms =  ['18.97']\n",
      "..........\n",
      "Episode 660 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.061\n",
      "Max Norms =  ['23.38']\n",
      "..........\n",
      "Episode 670 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.006\n",
      "Max Norms =  ['24.72']\n",
      "..........\n",
      "Episode 680 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.015\n",
      "Max Norms =  ['21.39']\n",
      "..........\n",
      "Episode 690 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.023\n",
      "Max Norms =  ['10.79']\n",
      "..........\n",
      "Episode 700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.943\n",
      "Max Norms =  ['22.23']\n",
      "..........\n",
      "Episode 710 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.884\n",
      "Max Norms =  ['22.25']\n",
      "..........\n",
      "Episode 720 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.829\n",
      "Max Norms =  ['17.97']\n",
      "..........\n",
      "Episode 730 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.777\n",
      "Max Norms =  ['29.81']\n",
      "..........\n",
      "Episode 740 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.683\n",
      "Max Norms =  ['27.62']\n",
      "..........\n",
      "Episode 750 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.741\n",
      "Max Norms =  ['15.56']\n",
      "..........\n",
      "Episode 760 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.708\n",
      "Max Norms =  ['14.69']\n",
      "..........\n",
      "Episode 770 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.689\n",
      "Max Norms =  ['31.59']\n",
      "..........\n",
      "Episode 780 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.66\n",
      "Max Norms =  ['8.64']\n",
      "..........\n",
      "Episode 790 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.684\n",
      "Max Norms =  ['13.42']\n",
      "..........\n",
      "Episode 800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.637\n",
      "Max Norms =  ['16.66']\n",
      "..........\n",
      "Episode 810 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.577\n",
      "Max Norms =  ['27.64']\n",
      "..........\n",
      "Episode 820 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.561\n",
      "Max Norms =  ['20.11']\n",
      "..........\n",
      "Episode 830 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.537\n",
      "Max Norms =  ['25.19']\n",
      "..........\n",
      "Episode 840 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.503\n",
      "Max Norms =  ['29.08']\n",
      "..........\n",
      "Episode 850 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.484\n",
      "Max Norms =  ['13.78']\n",
      "..........\n",
      "Episode 860 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.466\n",
      "Max Norms =  ['23.04']\n",
      "..........\n",
      "Episode 870 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.469\n",
      "Max Norms =  ['19.85']\n",
      "..........\n",
      "Episode 880 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.473\n",
      "Max Norms =  ['30.16']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 890 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.562\n",
      "Max Norms =  ['31.37']\n",
      "..........\n",
      "Episode 900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.546\n",
      "Max Norms =  ['19.76']\n",
      "..........\n",
      "Episode 910 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.486\n",
      "Max Norms =  ['30.26']\n",
      "..........\n",
      "Episode 920 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.44\n",
      "Max Norms =  ['24.94']\n",
      "..........\n",
      "Episode 930 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.417\n",
      "Max Norms =  ['12.44']\n",
      "..........\n",
      "Episode 940 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.387\n",
      "Max Norms =  ['14.97']\n",
      "..........\n",
      "Episode 950 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.359\n",
      "Max Norms =  ['35.22']\n",
      "..........\n",
      "Episode 960 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.422\n",
      "Max Norms =  ['14.63']\n",
      "..........\n",
      "Episode 970 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.391\n",
      "Max Norms =  ['21.25']\n",
      "..........\n",
      "Episode 980 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.372\n",
      "Max Norms =  ['18.03']\n",
      "..........\n",
      "Episode 990 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.356\n",
      "Max Norms =  ['38.36']\n",
      "..........\n",
      "Episode 1000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.321\n",
      "Max Norms =  ['9.32']\n",
      "..........\n",
      "Episode 1010 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.337\n",
      "Max Norms =  ['14.29']\n",
      "..........\n",
      "Episode 1020 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.342\n",
      "Max Norms =  ['12.10']\n",
      "..........\n",
      "Episode 1030 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.271\n",
      "Max Norms =  ['16.03']\n",
      "..........\n",
      "Episode 1040 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.283\n",
      "Max Norms =  ['20.29']\n",
      "..........\n",
      "Episode 1050 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.264\n",
      "Max Norms =  ['30.92']\n",
      "..........\n",
      "Episode 1060 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.249\n",
      "Max Norms =  ['20.08']\n",
      "..........\n",
      "Episode 1070 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.215\n",
      "Max Norms =  ['24.97']\n",
      "..........\n",
      "Episode 1080 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.204\n",
      "Max Norms =  ['27.85']\n",
      "..........\n",
      "Episode 1090 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.241\n",
      "Max Norms =  ['20.33']\n",
      "..........\n",
      "Episode 1100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.275\n",
      "Max Norms =  ['23.51']\n",
      "..........\n",
      "Episode 1110 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.259\n",
      "Max Norms =  ['18.28']\n",
      "..........\n",
      "Episode 1120 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.186\n",
      "Max Norms =  ['19.73']\n",
      "..........\n",
      "Episode 1130 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.178\n",
      "Max Norms =  ['33.46']\n",
      "..........\n",
      "Episode 1140 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.189\n",
      "Max Norms =  ['17.78']\n",
      "..........\n",
      "Episode 1150 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.239\n",
      "Max Norms =  ['25.84']\n",
      "..........\n",
      "Episode 1160 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.235\n",
      "Max Norms =  ['11.96']\n",
      "..........\n",
      "Episode 1170 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.262\n",
      "Max Norms =  ['26.30']\n",
      "..........\n",
      "Episode 1180 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.284\n",
      "Max Norms =  ['20.24']\n",
      "..........\n",
      "Episode 1190 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.295\n",
      "Max Norms =  ['22.70']\n",
      "..........\n",
      "Episode 1200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.238\n",
      "Max Norms =  ['16.08']\n",
      "..........\n",
      "Episode 1210 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.204\n",
      "Max Norms =  ['29.07']\n",
      "..........\n",
      "Episode 1220 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.166\n",
      "Max Norms =  ['10.98']\n",
      "..........\n",
      "Episode 1230 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.161\n",
      "Max Norms =  ['14.62']\n",
      "..........\n",
      "Episode 1240 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.164\n",
      "Max Norms =  ['14.51']\n",
      "..........\n",
      "Episode 1250 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.101\n",
      "Max Norms =  ['14.90']\n",
      "..........\n",
      "Episode 1260 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.083\n",
      "Max Norms =  ['24.09']\n",
      "..........\n",
      "Episode 1270 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.027\n",
      "Max Norms =  ['25.16']\n",
      "..........\n",
      "Episode 1280 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.081\n",
      "Max Norms =  ['16.07']\n",
      "..........\n",
      "Episode 1290 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.073\n",
      "Max Norms =  ['21.02']\n",
      "..........\n",
      "Episode 1300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.086\n",
      "Max Norms =  ['9.72']\n",
      "..........\n",
      "Episode 1310 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.038\n",
      "Max Norms =  ['25.03']\n",
      "..........\n",
      "Episode 1320 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.042\n",
      "Max Norms =  ['20.58']\n",
      "..........\n",
      "Episode 1330 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.056\n",
      "Max Norms =  ['21.11']\n",
      "..........\n",
      "Episode 1340 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.041\n",
      "Max Norms =  ['31.79']\n",
      "..........\n",
      "Episode 1350 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.058\n",
      "Max Norms =  ['42.73']\n",
      "..........\n",
      "Episode 1360 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.063\n",
      "Max Norms =  ['20.45']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 1370 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.039\n",
      "Max Norms =  ['19.86']\n",
      "..........\n",
      "Episode 1380 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.996\n",
      "Max Norms =  ['14.02']\n",
      "..........\n",
      "Episode 1390 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.997\n",
      "Max Norms =  ['15.19']\n",
      "..........\n",
      "Episode 1400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.997\n",
      "Max Norms =  ['18.23']\n",
      "..........\n",
      "Episode 1410 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.97\n",
      "Max Norms =  ['17.31']\n",
      "..........\n",
      "Episode 1420 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.944\n",
      "Max Norms =  ['16.99']\n",
      "..........\n",
      "Episode 1430 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.959\n",
      "Max Norms =  ['18.30']\n",
      "..........\n",
      "Episode 1440 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.945\n",
      "Max Norms =  ['23.11']\n",
      "..........\n",
      "Episode 1450 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.941\n",
      "Max Norms =  ['20.95']\n",
      "..........\n",
      "Episode 1460 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.918\n",
      "Max Norms =  ['47.58']\n",
      "..........\n",
      "Episode 1470 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 5.955\n",
      "Max Norms =  ['39.61']\n",
      "..........\n",
      "Episode 1480 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.922\n",
      "Max Norms =  ['23.94']\n",
      "..........\n",
      "Episode 1490 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.93\n",
      "Max Norms =  ['21.98']\n",
      "..........\n",
      "Episode 1500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.908\n",
      "Max Norms =  ['17.46']\n",
      "..........\n",
      "Episode 1510 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.878\n",
      "Max Norms =  ['29.80']\n",
      "..........\n",
      "Episode 1520 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.842\n",
      "Max Norms =  ['25.00']\n",
      "..........\n",
      "Episode 1530 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.829\n",
      "Max Norms =  ['19.47']\n",
      "..........\n",
      "Episode 1540 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.797\n",
      "Max Norms =  ['29.24']\n",
      "..........\n",
      "Episode 1550 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.844\n",
      "Max Norms =  ['36.97']\n",
      "..........\n",
      "Episode 1560 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 5.849\n",
      "Max Norms =  ['27.86']\n",
      "..........\n",
      "Episode 1570 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 5.864\n",
      "Max Norms =  ['19.56']\n",
      "..........\n",
      "Episode 1580 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.907\n",
      "Max Norms =  ['16.79']\n",
      "..........\n",
      "Episode 1590 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.897\n",
      "Max Norms =  ['10.09']\n",
      "..........\n",
      "Episode 1600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 5.898\n",
      "Max Norms =  ['12.54']\n",
      "..........\n",
      "Episode 1610 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.86\n",
      "Max Norms =  ['28.65']\n",
      "..........\n",
      "Episode 1620 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.845\n",
      "Max Norms =  ['31.13']\n",
      "..........\n",
      "Episode 1630 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.86\n",
      "Max Norms =  ['36.33']\n",
      "..........\n",
      "Episode 1640 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.902\n",
      "Max Norms =  ['8.03']\n",
      "..........\n",
      "Episode 1650 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.921\n",
      "Max Norms =  ['26.32']\n",
      "..........\n",
      "Episode 1660 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.919\n",
      "Max Norms =  ['21.74']\n",
      "..........\n",
      "Episode 1670 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.935\n",
      "Max Norms =  ['12.25']\n",
      "..........\n",
      "Episode 1680 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.961\n",
      "Max Norms =  ['20.49']\n",
      "..........\n",
      "Episode 1690 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.963\n",
      "Max Norms =  ['12.22']\n",
      "..........\n",
      "Episode 1700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.918\n",
      "Max Norms =  ['21.01']\n",
      "..........\n",
      "Episode 1710 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.887\n",
      "Max Norms =  ['26.15']\n",
      "..........\n",
      "Episode 1720 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.859\n",
      "Max Norms =  ['13.13']\n",
      "..........\n",
      "Episode 1730 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.873\n",
      "Max Norms =  ['12.61']\n",
      "..........\n",
      "Episode 1740 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.903\n",
      "Max Norms =  ['8.61']\n",
      "..........\n",
      "Episode 1750 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.932\n",
      "Max Norms =  ['17.71']\n",
      "..........\n",
      "Episode 1760 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 5.93\n",
      "Max Norms =  ['16.26']\n",
      "..........\n",
      "Episode 1770 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.889\n",
      "Max Norms =  ['17.58']\n",
      "..........\n",
      "Episode 1780 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.832\n",
      "Max Norms =  ['10.08']\n",
      "..........\n",
      "Episode 1790 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.837\n",
      "Max Norms =  ['9.50']\n",
      "..........\n",
      "Episode 1800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.805\n",
      "Max Norms =  ['60.56']\n",
      "..........\n",
      "Episode 1810 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.775\n",
      "Max Norms =  ['15.91']\n",
      "..........\n",
      "Episode 1820 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.739\n",
      "Max Norms =  ['26.36']\n",
      "..........\n",
      "Episode 1830 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.726\n",
      "Max Norms =  ['40.53']\n",
      "..........\n",
      "Episode 1840 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.753\n",
      "Max Norms =  ['18.49']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 1850 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.748\n",
      "Max Norms =  ['7.45']\n",
      "..........\n",
      "Episode 1860 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.781\n",
      "Max Norms =  ['44.97']\n",
      "..........\n",
      "Episode 1870 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.811\n",
      "Max Norms =  ['9.10']\n",
      "..........\n",
      "Episode 1880 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.781\n",
      "Max Norms =  ['1.34']\n",
      "..........\n",
      "Episode 1890 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.773\n",
      "Max Norms =  ['18.33']\n",
      "..........\n",
      "Episode 1900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.776\n",
      "Max Norms =  ['18.21']\n",
      "..........\n",
      "Episode 1910 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.836\n",
      "Max Norms =  ['18.61']\n",
      "..........\n",
      "Episode 1920 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.901\n",
      "Max Norms =  ['14.56']\n",
      "..........\n",
      "Episode 1930 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.007\n",
      "Max Norms =  ['10.37']\n",
      "..........\n",
      "Episode 1940 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.121\n",
      "Max Norms =  ['6.72']\n",
      "..........\n",
      "Episode 1950 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.235\n",
      "Max Norms =  ['22.33']\n",
      "..........\n",
      "Episode 1960 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.345\n",
      "Max Norms =  ['13.27']\n",
      "..........\n",
      "Episode 1970 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.485\n",
      "Max Norms =  ['15.74']\n",
      "..........\n",
      "Episode 1980 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.594\n",
      "Max Norms =  ['5.99']\n",
      "..........\n",
      "Episode 1990 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.777\n",
      "Max Norms =  ['9.28']\n",
      "..........\n",
      "Episode 2000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.923\n",
      "Max Norms =  ['7.62']\n",
      "\n",
      "Training time: 180.53 sec\n",
      "Learner agent 0\n",
      "Load Drone Leader.\n",
      "..........\n",
      "Episode 10 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:42\tRunning mean: 46.14\n",
      "Max Norms =  ['9.70']\n",
      "..........\n",
      "Episode 20 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:53\tRunning mean: 46.71\n",
      "Max Norms =  ['14.21']\n",
      "..........\n",
      "Episode 30 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:39\tRunning mean: 47.1\n",
      "Max Norms =  ['11.35']\n",
      "..........\n",
      "Episode 40 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:55\tRunning mean: 46.97\n",
      "Max Norms =  ['20.06']\n",
      "..........\n",
      "Episode 50 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:41\tRunning mean: 47.11\n",
      "Max Norms =  ['12.10']\n",
      "..........\n",
      "Episode 60 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:49\tRunning mean: 47.26\n",
      "Max Norms =  ['14.86']\n",
      "..........\n",
      "Episode 70 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:56\tRunning mean: 47.45\n",
      "Max Norms =  ['18.16']\n",
      "..........\n",
      "Episode 80 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:50\tRunning mean: 47.47\n",
      "Max Norms =  ['12.29']\n",
      "..........\n",
      "Episode 90 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:41\tRunning mean: 47.44\n",
      "Max Norms =  ['9.33']\n",
      "..........\n",
      "Episode 100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:19\tRunning mean: 46.53\n",
      "Max Norms =  ['12.44']\n",
      "..........\n",
      "Episode 110 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:26\tRunning mean: 45.58\n",
      "Max Norms =  ['13.88']\n",
      "..........\n",
      "Episode 120 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:34\tRunning mean: 43.87\n",
      "Max Norms =  ['16.48']\n",
      "..........\n",
      "Episode 130 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:22\tRunning mean: 41.63\n",
      "Max Norms =  ['12.98']\n",
      "..........\n",
      "Episode 140 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 40.11\n",
      "Max Norms =  ['14.09']\n",
      "..........\n",
      "Episode 150 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:33\tRunning mean: 38.42\n",
      "Max Norms =  ['14.26']\n",
      "..........\n",
      "Episode 160 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:34\tRunning mean: 37.48\n",
      "Max Norms =  ['14.00']\n",
      "..........\n",
      "Episode 170 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:26\tRunning mean: 36.53\n",
      "Max Norms =  ['10.50']\n",
      "..........\n",
      "Episode 180 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:27\tRunning mean: 35.19\n",
      "Max Norms =  ['15.41']\n",
      "..........\n",
      "Episode 190 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:14\tRunning mean: 33.7\n",
      "Max Norms =  ['10.40']\n",
      "..........\n",
      "Episode 200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:33\tRunning mean: 32.61\n",
      "Max Norms =  ['21.74']\n",
      "..........\n",
      "Episode 210 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 30.96\n",
      "Max Norms =  ['16.50']\n",
      "..........\n",
      "Episode 220 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:24\tRunning mean: 28.92\n",
      "Max Norms =  ['14.95']\n",
      "..........\n",
      "Episode 230 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:19\tRunning mean: 26.97\n",
      "Max Norms =  ['12.00']\n",
      "..........\n",
      "Episode 240 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 25.16\n",
      "Max Norms =  ['20.39']\n",
      "..........\n",
      "Episode 250 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 23.51\n",
      "Max Norms =  ['17.76']\n",
      "..........\n",
      "Episode 260 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:12\tRunning mean: 22.3\n",
      "Max Norms =  ['18.83']\n",
      "..........\n",
      "Episode 270 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:18\tRunning mean: 21.13\n",
      "Max Norms =  ['19.44']\n",
      "..........\n",
      "Episode 280 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 19.84\n",
      "Max Norms =  ['17.88']\n",
      "..........\n",
      "Episode 290 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 18.71\n",
      "Max Norms =  ['19.18']\n",
      "..........\n",
      "Episode 300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 17.59\n",
      "Max Norms =  ['14.30']\n",
      "..........\n",
      "Episode 310 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 16.6\n",
      "Max Norms =  ['18.49']\n",
      "..........\n",
      "Episode 320 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 15.82\n",
      "Max Norms =  ['22.91']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 330 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 15.0\n",
      "Max Norms =  ['21.61']\n",
      "..........\n",
      "Episode 340 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 14.31\n",
      "Max Norms =  ['20.16']\n",
      "..........\n",
      "Episode 350 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 13.66\n",
      "Max Norms =  ['21.60']\n",
      "..........\n",
      "Episode 360 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 13.04\n",
      "Max Norms =  ['11.30']\n",
      "..........\n",
      "Episode 370 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 12.55\n",
      "Max Norms =  ['18.22']\n",
      "..........\n",
      "Episode 380 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 12.15\n",
      "Max Norms =  ['13.12']\n",
      "..........\n",
      "Episode 390 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 11.7\n",
      "Max Norms =  ['22.61']\n",
      "..........\n",
      "Episode 400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 11.29\n",
      "Max Norms =  ['28.46']\n",
      "..........\n",
      "Episode 410 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 11.03\n",
      "Max Norms =  ['33.73']\n",
      "..........\n",
      "Episode 420 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 10.68\n",
      "Max Norms =  ['22.86']\n",
      "..........\n",
      "Episode 430 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 10.42\n",
      "Max Norms =  ['18.92']\n",
      "..........\n",
      "Episode 440 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 10.21\n",
      "Max Norms =  ['15.55']\n",
      "..........\n",
      "Episode 450 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 9.982\n",
      "Max Norms =  ['12.53']\n",
      "..........\n",
      "Episode 460 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 9.793\n",
      "Max Norms =  ['17.34']\n",
      "..........\n",
      "Episode 470 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 9.515\n",
      "Max Norms =  ['19.91']\n",
      "..........\n",
      "Episode 480 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 9.341\n",
      "Max Norms =  ['18.24']\n",
      "..........\n",
      "Episode 490 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 9.109\n",
      "Max Norms =  ['22.26']\n",
      "..........\n",
      "Episode 500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 8.908\n",
      "Max Norms =  ['12.92']\n",
      "..........\n",
      "Episode 510 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.755\n",
      "Max Norms =  ['20.54']\n",
      "..........\n",
      "Episode 520 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 8.615\n",
      "Max Norms =  ['16.75']\n",
      "..........\n",
      "Episode 530 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.461\n",
      "Max Norms =  ['18.40']\n",
      "..........\n",
      "Episode 540 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 8.331\n",
      "Max Norms =  ['30.27']\n",
      "..........\n",
      "Episode 550 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 8.27\n",
      "Max Norms =  ['28.30']\n",
      "..........\n",
      "Episode 560 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 8.186\n",
      "Max Norms =  ['22.33']\n",
      "..........\n",
      "Episode 570 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.179\n",
      "Max Norms =  ['38.34']\n",
      "..........\n",
      "Episode 580 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 8.211\n",
      "Max Norms =  ['30.74']\n",
      "..........\n",
      "Episode 590 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 8.18\n",
      "Max Norms =  ['21.71']\n",
      "..........\n",
      "Episode 600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 8.018\n",
      "Max Norms =  ['32.25']\n",
      "..........\n",
      "Episode 610 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.957\n",
      "Max Norms =  ['13.22']\n",
      "..........\n",
      "Episode 620 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.771\n",
      "Max Norms =  ['34.57']\n",
      "..........\n",
      "Episode 630 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.751\n",
      "Max Norms =  ['13.30']\n",
      "..........\n",
      "Episode 640 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 7.728\n",
      "Max Norms =  ['20.70']\n",
      "..........\n",
      "Episode 650 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.573\n",
      "Max Norms =  ['16.13']\n",
      "..........\n",
      "Episode 660 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.595\n",
      "Max Norms =  ['29.59']\n",
      "..........\n",
      "Episode 670 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.529\n",
      "Max Norms =  ['13.62']\n",
      "..........\n",
      "Episode 680 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.421\n",
      "Max Norms =  ['14.76']\n",
      "..........\n",
      "Episode 690 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 7.438\n",
      "Max Norms =  ['20.93']\n",
      "..........\n",
      "Episode 700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 7.404\n",
      "Max Norms =  ['21.08']\n",
      "..........\n",
      "Episode 710 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.375\n",
      "Max Norms =  ['12.44']\n",
      "..........\n",
      "Episode 720 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.3\n",
      "Max Norms =  ['12.65']\n",
      "..........\n",
      "Episode 730 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 7.243\n",
      "Max Norms =  ['12.48']\n",
      "..........\n",
      "Episode 740 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.183\n",
      "Max Norms =  ['25.94']\n",
      "..........\n",
      "Episode 750 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.078\n",
      "Max Norms =  ['15.10']\n",
      "..........\n",
      "Episode 760 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.042\n",
      "Max Norms =  ['16.78']\n",
      "..........\n",
      "Episode 770 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 7.103\n",
      "Max Norms =  ['35.83']\n",
      "..........\n",
      "Episode 780 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 7.016\n",
      "Max Norms =  ['30.85']\n",
      "..........\n",
      "Episode 790 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.948\n",
      "Max Norms =  ['31.85']\n",
      "..........\n",
      "Episode 800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.926\n",
      "Max Norms =  ['34.60']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 810 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.923\n",
      "Max Norms =  ['39.43']\n",
      "..........\n",
      "Episode 820 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.834\n",
      "Max Norms =  ['20.04']\n",
      "..........\n",
      "Episode 830 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:8\tRunning mean: 6.85\n",
      "Max Norms =  ['16.58']\n",
      "..........\n",
      "Episode 840 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.816\n",
      "Max Norms =  ['35.45']\n",
      "..........\n",
      "Episode 850 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.777\n",
      "Max Norms =  ['23.13']\n",
      "..........\n",
      "Episode 860 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.798\n",
      "Max Norms =  ['24.92']\n",
      "..........\n",
      "Episode 870 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.712\n",
      "Max Norms =  ['10.11']\n",
      "..........\n",
      "Episode 880 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 6.595\n",
      "Max Norms =  ['22.85']\n",
      "..........\n",
      "Episode 890 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.664\n",
      "Max Norms =  ['18.10']\n",
      "..........\n",
      "Episode 900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.772\n",
      "Max Norms =  ['24.45']\n",
      "..........\n",
      "Episode 910 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.737\n",
      "Max Norms =  ['42.33']\n",
      "..........\n",
      "Episode 920 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.645\n",
      "Max Norms =  ['31.72']\n",
      "..........\n",
      "Episode 930 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.506\n",
      "Max Norms =  ['18.42']\n",
      "..........\n",
      "Episode 940 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 6.361\n",
      "Max Norms =  ['27.42']\n",
      "..........\n",
      "Episode 950 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 6.279\n",
      "Max Norms =  ['28.53']\n",
      "..........\n",
      "Episode 960 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.252\n",
      "Max Norms =  ['15.40']\n",
      "..........\n",
      "Episode 970 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 6.271\n",
      "Max Norms =  ['18.56']\n",
      "..........\n",
      "Episode 980 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 6.131\n",
      "Max Norms =  ['64.00']\n",
      "..........\n",
      "Episode 990 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 5.929\n",
      "Max Norms =  ['25.71']\n",
      "..........\n",
      "Episode 1000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 5.907\n",
      "Max Norms =  ['12.83']\n",
      "..........\n",
      "Episode 1010 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 5.773\n",
      "Max Norms =  ['30.37']\n",
      "..........\n",
      "Episode 1020 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 5.614\n",
      "Max Norms =  ['20.83']\n",
      "..........\n",
      "Episode 1030 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 5.509\n",
      "Max Norms =  ['36.47']\n",
      "..........\n",
      "Episode 1040 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 5.374\n",
      "Max Norms =  ['41.62']\n",
      "..........\n",
      "Episode 1050 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 5.09\n",
      "Max Norms =  ['20.48']\n",
      "..........\n",
      "Episode 1060 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 4.921\n",
      "Max Norms =  ['8.44']\n",
      "..........\n",
      "Episode 1070 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 4.747\n",
      "Max Norms =  ['20.42']\n",
      "..........\n",
      "Episode 1080 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 4.674\n",
      "Max Norms =  ['22.08']\n",
      "..........\n",
      "Episode 1090 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 4.488\n",
      "Max Norms =  ['22.89']\n",
      "..........\n",
      "Episode 1100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:9\tRunning mean: 4.521\n",
      "Max Norms =  ['29.24']\n",
      "..........\n",
      "Episode 1110 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 4.361\n",
      "Max Norms =  ['52.85']\n",
      "..........\n",
      "Episode 1120 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 4.278\n",
      "Max Norms =  ['18.88']\n",
      "..........\n",
      "Episode 1130 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 4.089\n",
      "Max Norms =  ['17.00']\n",
      "..........\n",
      "Episode 1140 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 3.938\n",
      "Max Norms =  ['34.15']\n",
      "..........\n",
      "Episode 1150 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 4.031\n",
      "Max Norms =  ['64.70']\n",
      "..........\n",
      "Episode 1160 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 3.885\n",
      "Max Norms =  ['19.23']\n",
      "..........\n",
      "Episode 1170 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 3.79\n",
      "Max Norms =  ['17.80']\n",
      "..........\n",
      "Episode 1180 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 3.802\n",
      "Max Norms =  ['13.69']\n",
      "..........\n",
      "Episode 1190 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 3.83\n",
      "Max Norms =  ['46.77']\n",
      "..........\n",
      "Episode 1200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 3.637\n",
      "Max Norms =  ['27.52']\n",
      "..........\n",
      "Episode 1210 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 3.528\n",
      "Max Norms =  ['27.43']\n",
      "..........\n",
      "Episode 1220 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 3.446\n",
      "Max Norms =  ['27.00']\n",
      "..........\n",
      "Episode 1230 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 3.337\n",
      "Max Norms =  ['18.69']\n",
      "..........\n",
      "Episode 1240 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 3.265\n",
      "Max Norms =  ['43.67']\n",
      "..........\n",
      "Episode 1250 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 3.199\n",
      "Max Norms =  ['28.19']\n",
      "..........\n",
      "Episode 1260 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 3.122\n",
      "Max Norms =  ['41.60']\n",
      "..........\n",
      "Episode 1270 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 3.012\n",
      "Max Norms =  ['26.46']\n",
      "..........\n",
      "Episode 1280 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 3.068\n",
      "Max Norms =  ['53.61']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 1290 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 3.031\n",
      "Max Norms =  ['31.31']\n",
      "..........\n",
      "Episode 1300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 3.058\n",
      "Max Norms =  ['35.76']\n",
      "..........\n",
      "Episode 1310 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 3.052\n",
      "Max Norms =  ['24.64']\n",
      "..........\n",
      "Episode 1320 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.98\n",
      "Max Norms =  ['40.08']\n",
      "..........\n",
      "Episode 1330 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 2.984\n",
      "Max Norms =  ['59.05']\n",
      "..........\n",
      "Episode 1340 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 2.919\n",
      "Max Norms =  ['30.92']\n",
      "..........\n",
      "Episode 1350 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 2.802\n",
      "Max Norms =  ['21.07']\n",
      "..........\n",
      "Episode 1360 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.821\n",
      "Max Norms =  ['32.48']\n",
      "..........\n",
      "Episode 1370 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.741\n",
      "Max Norms =  ['50.97']\n",
      "..........\n",
      "Episode 1380 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.69\n",
      "Max Norms =  ['38.05']\n",
      "..........\n",
      "Episode 1390 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.631\n",
      "Max Norms =  ['30.57']\n",
      "..........\n",
      "Episode 1400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.609\n",
      "Max Norms =  ['25.74']\n",
      "..........\n",
      "Episode 1410 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.58\n",
      "Max Norms =  ['55.14']\n",
      "..........\n",
      "Episode 1420 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.562\n",
      "Max Norms =  ['16.77']\n",
      "..........\n",
      "Episode 1430 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 2.549\n",
      "Max Norms =  ['31.98']\n",
      "..........\n",
      "Episode 1440 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.504\n",
      "Max Norms =  ['26.34']\n",
      "..........\n",
      "Episode 1450 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.486\n",
      "Max Norms =  ['40.47']\n",
      "..........\n",
      "Episode 1460 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.497\n",
      "Max Norms =  ['35.90']\n",
      "..........\n",
      "Episode 1470 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.601\n",
      "Max Norms =  ['18.57']\n",
      "..........\n",
      "Episode 1480 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 2.563\n",
      "Max Norms =  ['39.42']\n",
      "..........\n",
      "Episode 1490 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.595\n",
      "Max Norms =  ['39.28']\n",
      "..........\n",
      "Episode 1500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.567\n",
      "Max Norms =  ['69.78']\n",
      "..........\n",
      "Episode 1510 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 2.52\n",
      "Max Norms =  ['23.61']\n",
      "..........\n",
      "Episode 1520 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.529\n",
      "Max Norms =  ['25.87']\n",
      "..........\n",
      "Episode 1530 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.459\n",
      "Max Norms =  ['14.72']\n",
      "..........\n",
      "Episode 1540 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.501\n",
      "Max Norms =  ['17.45']\n",
      "..........\n",
      "Episode 1550 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.558\n",
      "Max Norms =  ['17.90']\n",
      "..........\n",
      "Episode 1560 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.495\n",
      "Max Norms =  ['36.51']\n",
      "..........\n",
      "Episode 1570 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.494\n",
      "Max Norms =  ['29.50']\n",
      "..........\n",
      "Episode 1580 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.523\n",
      "Max Norms =  ['38.90']\n",
      "..........\n",
      "Episode 1590 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.501\n",
      "Max Norms =  ['46.96']\n",
      "..........\n",
      "Episode 1600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.424\n",
      "Max Norms =  ['28.84']\n",
      "..........\n",
      "Episode 1610 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.326\n",
      "Max Norms =  ['28.14']\n",
      "..........\n",
      "Episode 1620 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.312\n",
      "Max Norms =  ['20.85']\n",
      "..........\n",
      "Episode 1630 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.283\n",
      "Max Norms =  ['57.15']\n",
      "..........\n",
      "Episode 1640 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.275\n",
      "Max Norms =  ['35.65']\n",
      "..........\n",
      "Episode 1650 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 2.26\n",
      "Max Norms =  ['41.69']\n",
      "..........\n",
      "Episode 1660 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 2.311\n",
      "Max Norms =  ['45.83']\n",
      "..........\n",
      "Episode 1670 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.253\n",
      "Max Norms =  ['35.98']\n",
      "..........\n",
      "Episode 1680 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.267\n",
      "Max Norms =  ['59.07']\n",
      "..........\n",
      "Episode 1690 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.223\n",
      "Max Norms =  ['16.33']\n",
      "..........\n",
      "Episode 1700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.154\n",
      "Max Norms =  ['70.70']\n",
      "..........\n",
      "Episode 1710 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 2.246\n",
      "Max Norms =  ['30.36']\n",
      "..........\n",
      "Episode 1720 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.184\n",
      "Max Norms =  ['36.92']\n",
      "..........\n",
      "Episode 1730 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.06\n",
      "Max Norms =  ['43.45']\n",
      "..........\n",
      "Episode 1740 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.055\n",
      "Max Norms =  ['51.03']\n",
      "..........\n",
      "Episode 1750 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.059\n",
      "Max Norms =  ['25.02']\n",
      "..........\n",
      "Episode 1760 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 2.036\n",
      "Max Norms =  ['82.77']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 1770 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.096\n",
      "Max Norms =  ['73.44']\n",
      "..........\n",
      "Episode 1780 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.029\n",
      "Max Norms =  ['29.84']\n",
      "..........\n",
      "Episode 1790 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.094\n",
      "Max Norms =  ['34.01']\n",
      "..........\n",
      "Episode 1800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.093\n",
      "Max Norms =  ['25.37']\n",
      "..........\n",
      "Episode 1810 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.141\n",
      "Max Norms =  ['21.10']\n",
      "..........\n",
      "Episode 1820 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.1\n",
      "Max Norms =  ['49.45']\n",
      "..........\n",
      "Episode 1830 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.07\n",
      "Max Norms =  ['51.89']\n",
      "..........\n",
      "Episode 1840 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 2.015\n",
      "Max Norms =  ['23.57']\n",
      "..........\n",
      "Episode 1850 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 1.966\n",
      "Max Norms =  ['59.03']\n",
      "..........\n",
      "Episode 1860 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 1.932\n",
      "Max Norms =  ['72.20']\n",
      "..........\n",
      "Episode 1870 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 1.93\n",
      "Max Norms =  ['36.97']\n",
      "..........\n",
      "Episode 1880 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 1.879\n",
      "Max Norms =  ['32.80']\n",
      "..........\n",
      "Episode 1890 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 1.909\n",
      "Max Norms =  ['40.96']\n",
      "..........\n",
      "Episode 1900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 1.85\n",
      "Max Norms =  ['28.68']\n",
      "..........\n",
      "Episode 1910 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 1.798\n",
      "Max Norms =  ['73.13']\n",
      "..........\n",
      "Episode 1920 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 1.864\n",
      "Max Norms =  ['34.76']\n",
      "..........\n",
      "Episode 1930 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 1.859\n",
      "Max Norms =  ['22.62']\n",
      "..........\n",
      "Episode 1940 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 1.824\n",
      "Max Norms =  ['75.69']\n",
      "..........\n",
      "Episode 1950 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 1.784\n",
      "Max Norms =  ['14.12']\n",
      "..........\n",
      "Episode 1960 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 1.766\n",
      "Max Norms =  ['28.22']\n",
      "..........\n",
      "Episode 1970 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 1.719\n",
      "Max Norms =  ['45.51']\n",
      "..........\n",
      "Episode 1980 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 1.679\n",
      "Max Norms =  ['35.79']\n",
      "..........\n",
      "Episode 1990 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 1.632\n",
      "Max Norms =  ['59.69']\n",
      "..........\n",
      "Episode 2000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 1.669\n",
      "Max Norms =  ['80.39']\n",
      "\n",
      "Training time: 181.51 sec\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import deque\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Initialize environment\n",
    "game = \"Crossing\"\n",
    "num_crawler_actions = 8                     # Crawlers are capable of 8 actions\n",
    "num_drone_actions = 12                      # Drones are capable of 12 actions\n",
    "num_goal_params = 2    # Goal has 2 parameter\n",
    "\n",
    "experiment = '1T-1L/strategist/'    # 1 team of 1 drone leader directed by a strategist\n",
    "\n",
    "# Map and Parameter sets\n",
    "map_name = \"food_d37_river_w1_d25\"  \n",
    "parameters =[ \n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':0.5, \\\n",
    "             'game_steps':300, 'seed': 0},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':0.5, \\\n",
    "             'game_steps':300, 'seed': 7},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':0.5, \\\n",
    "             'game_steps':300, 'seed': 54}\n",
    "            ]\n",
    "\n",
    "temp_end = 1.0   # temp parameter is annealed from the value stored in parameters['temp_start'] to 1.0 \n",
    "\n",
    "# Initialize training parameters\n",
    "warm_start = False\n",
    "num_frames = 7      # environ observation consists of a list of stacked frames per agent\n",
    "max_episodes = 2000\n",
    "\n",
    "render = True    # This turns on rendering every save so that agents' behavior can be observed\n",
    "SPEED = 1/30\n",
    "second_pile_x = 50  # x-coordinate of the 2nd food pile\n",
    "\n",
    "log_interval = 10\n",
    "save_interval = 20\n",
    "\n",
    "# These trainer parameters works for Atari Breakout\n",
    "gamma = 0.99  \n",
    "lr = 1e-2\n",
    "\n",
    "# Initialize agents parameters\n",
    "#   1 agents - 1 learning agents, 0 trained agent, 0 random agent\n",
    "num_learners = 1\n",
    "num_trained = 0\n",
    "num_rdn = 0\n",
    "\n",
    "num_statics = num_trained + num_rdn\n",
    "num_agents = num_learners + num_statics  \n",
    "\n",
    "# The main code starts here!!!\n",
    "\n",
    "for parameter in parameters:   # Go down the list of parameter sets\n",
    "    \n",
    "    start = time.clock()  # time the training\n",
    "    \n",
    "    torch.manual_seed(parameter['seed'])\n",
    "    situation = 'droneleaderfc32_seed_'+str(parameter['seed'])\n",
    "    temp_start = parameter['temp_start']\n",
    "    river_penalty = parameter['river_penalty']\n",
    "    max_frames = parameter['game_steps']\n",
    "    \n",
    "    # Set up parameters of agents and teams as inputs into CrossingEnv\n",
    "    teams_params = [\n",
    "        {'name': 'Vikings', 'color': 'deepskyblue', \n",
    "         'culture': {'name':'pacifist_leadfollow','laser_penalty':-1.0,'target_reward':parameter['target_reward']},\n",
    "         'roles': ['leader','follower'],\n",
    "         'target_zone': None, 'banned_zone': None},\n",
    "    ]\n",
    "    agents_params = [\n",
    "        {'id': 0, 'team': 'Vikings', 'color': 'royalblue', 'type': 'drone',    \\\n",
    "         'role': 'leader', 'start': (3,9)},\n",
    "    ]\n",
    "\n",
    "    # Data structure for agents\n",
    "    agents = []\n",
    "    actions = []\n",
    "    log_probs = []\n",
    "    tags = []\n",
    "    rewards = []\n",
    "    deltas = []   # 6-2-2019 delta coordinates\n",
    "    optimizers = []\n",
    "\n",
    "    # Cold start\n",
    "    if warm_start is False:\n",
    "   \n",
    "        # Initialize learner agents, then load static agents (trained followed by random)\n",
    "        for i in range(num_learners):\n",
    "            \n",
    "            print(\"Learner agent {}\".format(i))\n",
    "            \n",
    "            # Initialize agent policy based on type\n",
    "            if agents_params[i]['type'] is 'crawler':\n",
    "                agents.append(Crawler_Policy(num_frames, num_crawler_actions, i))\n",
    "            elif agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'follower':\n",
    "                agents.append(Drone_Policy(num_frames, num_drone_actions, i)) \n",
    "            elif agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'leader':\n",
    "                print(\"Load Drone Leader.\")\n",
    "                agents.append(DroneLeader_FC32(num_goal_params, num_drone_actions, i)) \n",
    "            else:\n",
    "                raise Exception('Unexpected agent type: {}'.format(agents_params[i]['type']))\n",
    "            \n",
    "            optimizers.append(optim.Adam(agents[i].parameters(), lr=lr))\n",
    "        \n",
    "            # set up optimizer - this works for Atari Breakout\n",
    "            # optimizers.append(optim.RMSprop(agents[i].parameters(), lr=lr, weight_decay=0.1)) \n",
    "        \n",
    "        for i in range(num_learners, num_learners+num_trained):\n",
    "            print (\"Learning with trained agents - not implemented yet!\")\n",
    "            raise\n",
    "            \"\"\"\n",
    "            Disable for now! No need to train with trained agents.\n",
    "            agents.append(Crawler_Policy(num_frames, num_crawler_actions, i))\n",
    "            agents[i].load_weights()         # load weight for static agent        \n",
    "            \"\"\"\n",
    "        for i in range(num_learners+num_trained, num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "\n",
    "    \n",
    "        # Initialize all agent data\n",
    "        actions = [0 for i in range(num_agents)]\n",
    "        log_probs = [0 for i in range(num_agents)]\n",
    "        tags = [0 for i in range(num_agents)]\n",
    "        rewards = [0 for i in range(num_agents)]\n",
    "        deltas = [0 for i in range(num_agents)]\n",
    "\n",
    "        # Keep track of rewards learned by learners\n",
    "        episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "        running_reward = [None for i in range(num_learners)]   # running average\n",
    "        running_rewards = [[] for i in range(num_learners)]   # history of running averages\n",
    "        best_reward = [0 for i in range(num_learners)]    # best running average (for storing best_model)\n",
    "        \n",
    "        # 6-2-2019 Keep track of distance from goal achieved by droneleader\n",
    "        episode_delta = 0   # distance from goal for an episode\n",
    "        running_delta = None   # running distance from goal\n",
    "        running_deltas = []    # history of running distance from goal\n",
    "        best_delta = 0    # best running distance from goal (for storing best_model)        \n",
    "        \n",
    "        # Keep track of num learners who has crossed over to the 2nd food pile\n",
    "        crossed = [0 for i in range(num_learners)]      # whether an agent has crossed to the 2nd food pile  \n",
    "        episode_crossed = 0                             # num learners who has crossed for an episode\n",
    "        running_crossed = None         # running average\n",
    "        running_crossed_hist = []   # history of running averages\n",
    "\n",
    "        # This is to support warm start for training\n",
    "        prior_eps = 0\n",
    "\n",
    "    # Warm start\n",
    "    if warm_start:\n",
    "        print (\"Cannot warm start\")\n",
    "        raise\n",
    "    \n",
    "        \"\"\"\n",
    "        # Disable for now!  Need to ensure model can support training on GPU and game playing\n",
    "        # on both CPU and GPU.\n",
    "    \n",
    "        data_file = 'results/{}.p'.format(game)\n",
    "\n",
    "        try:\n",
    "            with open(data_file, 'rb') as f:\n",
    "                running_rewards = pickle.load(f)\n",
    "                running_reward = running_rewards[-1]\n",
    "\n",
    "            prior_eps = len(running_rewards)\n",
    "\n",
    "            model_file = 'saved_models/actor_critic_{}_ep_{}.p'.format(game, prior_eps)\n",
    "            with open(model_file, 'rb') as f:\n",
    "                # Model Save and Load Update: Include both model and optim parameters\n",
    "                saved_model = pickle.load(f)\n",
    "                model, optimizer = saved_model\n",
    "\n",
    "        except OSError:\n",
    "            print('Saved file not found. Creating new cold start model.')\n",
    "            model = Crawler_Policy(input_channels=num_frames, num_actions=num_crawler_actions)\n",
    "            optimizer = optim.RMSprop(model.parameters(), lr=lr,\n",
    "                                      weight_decay=0.1)\n",
    "            running_rewards = []\n",
    "            prior_eps = 0\n",
    "        \"\"\"\n",
    "    # Attach agents to their teams\n",
    "    # 4-28-2019 Add roles and types to enable multi-role teams\n",
    "\n",
    "    teams = []\n",
    "    # Team Vikings\n",
    "    teams.append(Team(name=teams_params[0]['name'],color=teams_params[0]['color'], \\\n",
    "                  culture=teams_params[0]['culture'], roles=teams_params[0]['roles'], \\\n",
    "                  agent_policies=[agents[0]], \\\n",
    "                  agent_roles = [agent['role'] for agent in agents_params[0:1]]))\n",
    "    \n",
    "    # 5-30-2019  Strategist accepts directorship of a team\n",
    "    suntzu = Strategist()\n",
    "    suntzu.accept(teams[0])   # Strategist accepts directorship of Team Viking\n",
    "    \n",
    "    env = CrossingEnv(agents=agents_params, teams=teams_params, \\\n",
    "                  map_name=map_name, river_penalty=river_penalty,  \\\n",
    "                  debug_window = False)   \n",
    "    \n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    if cuda:\n",
    "        for i in range(num_learners):    # Learning agents need to utilize GPU\n",
    "            agents[i].cuda()\n",
    "\n",
    "        \n",
    "    for ep in range(max_episodes):\n",
    "    \n",
    "        print('.', end='')  # To show progress\n",
    "    \n",
    "        # Anneal temperature from temp_start to temp_end\n",
    "        for i in range(num_learners):    # For learning agents\n",
    "            agents[i].temperature = max(temp_end, temp_start - (temp_start - temp_end) * (ep / max_episodes))\n",
    "\n",
    "        env_obs = env.reset()  # Env return observations\n",
    "\n",
    "        # For Debug only\n",
    "        # print (len(env_obs))\n",
    "        # print (env_obs[0].shape)\n",
    "    \n",
    "        # Unpack observations into data structure compatible with Crawler_Policy\n",
    "        agents_obs = unpack_env_obs(env_obs)\n",
    "        \n",
    "        # 5-30-2019 Strategist uses the obs space of its team eye as the big picture\n",
    "        game_space = agents_obs[suntzu.eyes[0].idx]\n",
    "        goals, topology = suntzu.generate_goals(game_space)\n",
    "        deltas = calc_norm_deltas(goals[0], env.agent_locations[0])\n",
    "        agents[0].deltas.append(deltas)   # Store a history of deltas for generating mission rewards\n",
    "\n",
    "        for i in range(num_learners):    # Reset agent info - laser tag statistics\n",
    "            agents[i].reset_info()   \n",
    "\n",
    "        # For Debug only\n",
    "        # print (len(agents_obs))\n",
    "        # print (agents_obs[0].shape)\n",
    "    \n",
    "        \"\"\"\n",
    "        For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "        state = np.stack([state]*num_frames)\n",
    "\n",
    "        # LSTM change - reset LSTM hidden units when episode begins\n",
    "        cx = Variable(torch.zeros(1, 256))\n",
    "        hx = Variable(torch.zeros(1, 256))\n",
    "        if cuda:\n",
    "            cx = cx.cuda()\n",
    "            hx = hx.cuda()\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize reward and agents crossed counters\n",
    "        episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "        episode_delta = 0                               # distance from goal for an episode\n",
    "        crossed = [0 for i in range(num_learners)]      # whether an agent has crossed to the 2nd food pile  \n",
    "        episode_crossed = 0                             # num learners who has crossed for an episode\n",
    "    \n",
    "        for frame in range(max_frames):\n",
    "\n",
    "            \"\"\"\n",
    "            For now, we do not implement LSTM\n",
    "            # Select action\n",
    "            # LSTM Change: Need to cycle hx and cx thru select_action\n",
    "            action, log_prob, value, (hx,cx)  = select_action(model, state, (hx,cx), cuda)        \n",
    "            \"\"\"\n",
    "\n",
    "            for i in range(num_learners):    # For learning agents\n",
    "                if agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'leader':\n",
    "                    # 6-02-2019 Simple droneleaders do not require obs space as input\n",
    "                    actions[i], log_probs[i] = select_action_strat_simple(agents[i], deltas, cuda)\n",
    "                else:    \n",
    "                    actions[i], log_probs[i] = select_action(agents[i], agents_obs[i], cuda)\n",
    "                \n",
    "                # Only crawlers can fire lasers\n",
    "                if agents_params[i]['type'] is 'crawler':\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                        \n",
    "                agents[i].saved_actions.append((log_probs[i]))\n",
    "            \n",
    "                # Do not implement LSTM for now\n",
    "                # actions[i].saved_actions.append((log_prob, value))\n",
    "            \n",
    "            for i in range(num_learners, num_learners+num_trained):\n",
    "                print (\"No trained agent exist yet!\")\n",
    "                raise\n",
    "            for i in range(num_learners+num_trained, num_agents):   # For random agents\n",
    "                actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                if actions[i] is 6:\n",
    "                    tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "            # For Debug only\n",
    "            # if frame % 20 == 0:\n",
    "            #    print (actions) \n",
    "            #    print (log_probs)\n",
    "            \n",
    "            # Perform step        \n",
    "            env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "            \"\"\"\n",
    "            For Debug only\n",
    "            print (env_obs)\n",
    "            print (reward)\n",
    "            print (done) \n",
    "            \"\"\"\n",
    "       \n",
    "            # Unpack observations into data structure compatible with Crawler_Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "            \n",
    "            load_info(agents, agents_params, info, narrate=False)   # Load agent info for AI agents\n",
    "            \n",
    "            # 5-30-2019 Strategist uses the obs space of its team eye as the big picture\n",
    "            game_space = agents_obs[suntzu.eyes[0].idx]\n",
    "            goals, topology = suntzu.generate_goals(game_space)\n",
    "            deltas = calc_norm_deltas(goals[0], env.agent_locations[0])\n",
    "            agents[0].deltas.append(deltas)   # Store a history of deltas for generating mission rewards\n",
    "\n",
    "            # For learner agents only, generate reward statistics and reward stack for policy gradient\n",
    "            for i in range(num_learners):\n",
    "                agents[i].rewards.append(reward[i])  # Stack rewards (for policy gradient)\n",
    "                episode_reward[i] += reward[i]   # accumulate episode reward \n",
    "            \n",
    "            \"\"\"\n",
    "            For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "            # Evict oldest diff add new diff to state\n",
    "            next_state = np.stack([next_state]*num_frames)\n",
    "            next_state[1:, :, :] = state[:-1, :, :]\n",
    "            state = next_state\n",
    "            \"\"\"\n",
    "            \n",
    "            if render and (ep % save_interval == 0):   # render 1 episode every save\n",
    "                env.render()\n",
    "                time.sleep(SPEED)  # Change speed of video rendering\n",
    "\n",
    "            if any(done):\n",
    "                print(\"Done after {} frames\".format(frame))\n",
    "                break\n",
    "\n",
    "        # Keep track num of agents who gather from 2nd food pile. Note that env.consumption tracks the \n",
    "        # agent index and location of apple gathered\n",
    "        for (i, loc) in env.consumption:\n",
    "            if loc[0] > second_pile_x:   # If x-cood of gathered apple is beyond a preset value, it is\n",
    "                                         # in the 2nd pile\n",
    "                crossed[i] = 1\n",
    "        episode_crossed = sum(crossed)   # sum up the num agents who crossed to 2nd pile for the episode\n",
    "                \n",
    "        # Update reward and crossed statistics for learners\n",
    "        for i in range(num_learners):\n",
    "            if running_reward[i] is None:\n",
    "                running_reward[i] = episode_reward[i]\n",
    "            running_reward[i] = running_reward[i] * 0.99 + episode_reward[i] * 0.01\n",
    "            running_rewards[i].append(running_reward[i])\n",
    "            \n",
    "        if running_crossed is None:\n",
    "            running_crossed = episode_crossed\n",
    "        running_crossed = running_crossed * 0.99 + episode_crossed * 0.01\n",
    "        running_crossed_hist.append(running_crossed)\n",
    "        \n",
    "        # 6-02-2019 Update distance from goal for droneleader\n",
    "        target_x, target_y = goals[0]\n",
    "        current_x, current_y = env.agent_locations[0]\n",
    "        episode_delta = abs(target_x - current_x) + abs(target_y - current_y)\n",
    "        \n",
    "        if running_delta is None:\n",
    "            running_delta = episode_delta\n",
    "        running_delta = running_delta * 0.99 + episode_delta * 0.01\n",
    "        running_deltas.append(running_delta)\n",
    "        \n",
    "                \n",
    "        # Track Episode #, temp and highest frames/episode\n",
    "        if (ep+prior_eps+1) % log_interval == 0: \n",
    "            verbose_str = '\\nEpisode {} complete'.format(ep+prior_eps+1)\n",
    "            # verbose_str += '\\tTemp = {:.4}'.format(model.temperature)\n",
    "            print(verbose_str)\n",
    "    \n",
    "            # Display rewards and running rewards for learning agents\n",
    "            for i in range(num_learners):\n",
    "                verbose_str = 'Learner:{}'.format(i)\n",
    "                verbose_str += '\\tReward total:{}'.format(episode_reward[i])\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_reward[i])\n",
    "                verbose_str += '\\tNum agents crossed: {}'.format(episode_crossed)\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_crossed)\n",
    "                verbose_str += '\\tDelta total:{}'.format(episode_delta)\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_delta)\n",
    "                print(verbose_str)\n",
    "    \n",
    "        # Update model\n",
    "        total_norms = finish_episode(teams, agents[0:num_learners], optimizers[0:num_learners], gamma, cuda)\n",
    "\n",
    "        if (ep+prior_eps+1) % log_interval == 0:\n",
    "            print('Max Norms = ',[\"%0.2f\" % i for i in total_norms])\n",
    "\n",
    "        if (ep+prior_eps+1) % save_interval == 0: \n",
    "            for i in range(num_learners):\n",
    "                model_dir = 'models/' + experiment + map_name\n",
    "                results_dir = 'results/' + experiment + map_name\n",
    "\n",
    "                model_file = model_dir+'/{}/t{}_rp{}_{}gs/MA{}_{}_ep{}.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames, \\\n",
    "                        i, game, ep+prior_eps+1)\n",
    "                data_file = results_dir+'/{}/t{}_rp{}_{}gs/MA{}_{}.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames, \\\n",
    "                        i, game)\n",
    "\n",
    "                os.makedirs(os.path.dirname(model_file), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(data_file), exist_ok=True)\n",
    "                \n",
    "                with open(model_file, 'wb') as f:\n",
    "                    # Model Save and Load Update: Include both model and optim parameters \n",
    "                    save_model(f, ep, agents[i], optimizers[i])\n",
    "\n",
    "                with open(data_file, 'wb') as f:\n",
    "                    pickle.dump(running_rewards[i], f)    \n",
    "             \n",
    "            crossed_file = results_dir+'/{}/t{}_rp{}_{}gs/Crossed.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames)\n",
    "            os.makedirs(os.path.dirname(crossed_file), exist_ok=True)\n",
    "            with open(crossed_file, 'wb') as f:\n",
    "                    pickle.dump(running_crossed_hist, f)\n",
    "\n",
    "            delta_file = results_dir+'/{}/t{}_rp{}_{}gs/Delta.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames)\n",
    "            os.makedirs(os.path.dirname(delta_file), exist_ok=True)\n",
    "            with open(delta_file, 'wb') as f:\n",
    "                    pickle.dump(running_deltas, f)\n",
    "\n",
    "    end = time.clock()\n",
    "    print('\\nTraining time: {:.2f} min'.format((end-start)/60.0))\n",
    "            \n",
    "    env.close()  # Close the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - DroneLeader_FC64\n",
    "\n",
    "Train DroneLeader_FC64 from 1 start point on the same map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner agent 0\n",
      "Load Drone Leader.\n",
      "..........\n",
      "Episode 10 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:61\tRunning mean: 42.17\n",
      "Max Norms =  ['22.96']\n",
      "..........\n",
      "Episode 20 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:58\tRunning mean: 43.92\n",
      "Max Norms =  ['20.21']\n",
      "..........\n",
      "Episode 30 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:58\tRunning mean: 45.63\n",
      "Max Norms =  ['14.24']\n",
      "..........\n",
      "Episode 40 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:56\tRunning mean: 47.09\n",
      "Max Norms =  ['20.40']\n",
      "..........\n",
      "Episode 50 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:67\tRunning mean: 48.01\n",
      "Max Norms =  ['19.13']\n",
      "..........\n",
      "Episode 60 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:60\tRunning mean: 48.78\n",
      "Max Norms =  ['19.69']\n",
      "........."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import deque\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Initialize environment\n",
    "game = \"Crossing\"\n",
    "num_crawler_actions = 8                     # Crawlers are capable of 8 actions\n",
    "num_drone_actions = 12                      # Drones are capable of 12 actions\n",
    "num_goal_params = 2    # Goal has 2 parameter\n",
    "\n",
    "experiment = '1T-1L/strategist/'    # 1 team of 1 drone leader directed by a strategist\n",
    "\n",
    "# Map and Parameter sets\n",
    "map_name = \"food_d37_river_w1_d25\"  \n",
    "parameters =[ \n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':0.5, \\\n",
    "             'game_steps':300, 'seed': 0},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':0.5, \\\n",
    "             'game_steps':300, 'seed': 7},\n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':0.5, \\\n",
    "             'game_steps':300, 'seed': 54}\n",
    "            ]\n",
    "\n",
    "temp_end = 1.0   # temp parameter is annealed from the value stored in parameters['temp_start'] to 1.0 \n",
    "\n",
    "# Initialize training parameters\n",
    "warm_start = False\n",
    "num_frames = 7      # environ observation consists of a list of stacked frames per agent\n",
    "max_episodes = 2000\n",
    "\n",
    "render = True    # This turns on rendering every save so that agents' behavior can be observed\n",
    "SPEED = 1/30\n",
    "second_pile_x = 50  # x-coordinate of the 2nd food pile\n",
    "\n",
    "log_interval = 10\n",
    "save_interval = 20\n",
    "\n",
    "# These trainer parameters works for Atari Breakout\n",
    "gamma = 0.99  \n",
    "lr = 1e-2\n",
    "\n",
    "# Initialize agents parameters\n",
    "#   1 agents - 1 learning agents, 0 trained agent, 0 random agent\n",
    "num_learners = 1\n",
    "num_trained = 0\n",
    "num_rdn = 0\n",
    "\n",
    "num_statics = num_trained + num_rdn\n",
    "num_agents = num_learners + num_statics  \n",
    "\n",
    "# The main code starts here!!!\n",
    "\n",
    "for parameter in parameters:   # Go down the list of parameter sets\n",
    "    \n",
    "    start = time.clock()  # time the training\n",
    "    \n",
    "    torch.manual_seed(parameter['seed'])\n",
    "    situation = 'droneleaderfc64_seed_'+str(parameter['seed'])\n",
    "    temp_start = parameter['temp_start']\n",
    "    river_penalty = parameter['river_penalty']\n",
    "    max_frames = parameter['game_steps']\n",
    "    \n",
    "    # Set up parameters of agents and teams as inputs into CrossingEnv\n",
    "    teams_params = [\n",
    "        {'name': 'Vikings', 'color': 'deepskyblue', \n",
    "         'culture': {'name':'pacifist_leadfollow','laser_penalty':-1.0,'target_reward':parameter['target_reward']},\n",
    "         'roles': ['leader','follower'],\n",
    "         'target_zone': None, 'banned_zone': None},\n",
    "    ]\n",
    "    agents_params = [\n",
    "        {'id': 0, 'team': 'Vikings', 'color': 'royalblue', 'type': 'drone',    \\\n",
    "         'role': 'leader', 'start': (3,9)},\n",
    "    ]\n",
    "\n",
    "    # Data structure for agents\n",
    "    agents = []\n",
    "    actions = []\n",
    "    log_probs = []\n",
    "    tags = []\n",
    "    rewards = []\n",
    "    deltas = []   # 6-2-2019 delta coordinates\n",
    "    optimizers = []\n",
    "\n",
    "    # Cold start\n",
    "    if warm_start is False:\n",
    "   \n",
    "        # Initialize learner agents, then load static agents (trained followed by random)\n",
    "        for i in range(num_learners):\n",
    "            \n",
    "            print(\"Learner agent {}\".format(i))\n",
    "            \n",
    "            # Initialize agent policy based on type\n",
    "            if agents_params[i]['type'] is 'crawler':\n",
    "                agents.append(Crawler_Policy(num_frames, num_crawler_actions, i))\n",
    "            elif agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'follower':\n",
    "                agents.append(Drone_Policy(num_frames, num_drone_actions, i)) \n",
    "            elif agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'leader':\n",
    "                print(\"Load Drone Leader.\")\n",
    "                agents.append(DroneLeader_FC64(num_goal_params, num_drone_actions, i)) \n",
    "            else:\n",
    "                raise Exception('Unexpected agent type: {}'.format(agents_params[i]['type']))\n",
    "            \n",
    "            optimizers.append(optim.Adam(agents[i].parameters(), lr=lr))\n",
    "        \n",
    "            # set up optimizer - this works for Atari Breakout\n",
    "            # optimizers.append(optim.RMSprop(agents[i].parameters(), lr=lr, weight_decay=0.1)) \n",
    "        \n",
    "        for i in range(num_learners, num_learners+num_trained):\n",
    "            print (\"Learning with trained agents - not implemented yet!\")\n",
    "            raise\n",
    "            \"\"\"\n",
    "            Disable for now! No need to train with trained agents.\n",
    "            agents.append(Crawler_Policy(num_frames, num_crawler_actions, i))\n",
    "            agents[i].load_weights()         # load weight for static agent        \n",
    "            \"\"\"\n",
    "        for i in range(num_learners+num_trained, num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "\n",
    "    \n",
    "        # Initialize all agent data\n",
    "        actions = [0 for i in range(num_agents)]\n",
    "        log_probs = [0 for i in range(num_agents)]\n",
    "        tags = [0 for i in range(num_agents)]\n",
    "        rewards = [0 for i in range(num_agents)]\n",
    "        deltas = [0 for i in range(num_agents)]\n",
    "\n",
    "        # Keep track of rewards learned by learners\n",
    "        episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "        running_reward = [None for i in range(num_learners)]   # running average\n",
    "        running_rewards = [[] for i in range(num_learners)]   # history of running averages\n",
    "        best_reward = [0 for i in range(num_learners)]    # best running average (for storing best_model)\n",
    "        \n",
    "        # 6-2-2019 Keep track of distance from goal achieved by droneleader\n",
    "        episode_delta = 0   # distance from goal for an episode\n",
    "        running_delta = None   # running distance from goal\n",
    "        running_deltas = []    # history of running distance from goal\n",
    "        best_delta = 0    # best running distance from goal (for storing best_model)        \n",
    "        \n",
    "        # Keep track of num learners who has crossed over to the 2nd food pile\n",
    "        crossed = [0 for i in range(num_learners)]      # whether an agent has crossed to the 2nd food pile  \n",
    "        episode_crossed = 0                             # num learners who has crossed for an episode\n",
    "        running_crossed = None         # running average\n",
    "        running_crossed_hist = []   # history of running averages\n",
    "\n",
    "        # This is to support warm start for training\n",
    "        prior_eps = 0\n",
    "\n",
    "    # Warm start\n",
    "    if warm_start:\n",
    "        print (\"Cannot warm start\")\n",
    "        raise\n",
    "    \n",
    "        \"\"\"\n",
    "        # Disable for now!  Need to ensure model can support training on GPU and game playing\n",
    "        # on both CPU and GPU.\n",
    "    \n",
    "        data_file = 'results/{}.p'.format(game)\n",
    "\n",
    "        try:\n",
    "            with open(data_file, 'rb') as f:\n",
    "                running_rewards = pickle.load(f)\n",
    "                running_reward = running_rewards[-1]\n",
    "\n",
    "            prior_eps = len(running_rewards)\n",
    "\n",
    "            model_file = 'saved_models/actor_critic_{}_ep_{}.p'.format(game, prior_eps)\n",
    "            with open(model_file, 'rb') as f:\n",
    "                # Model Save and Load Update: Include both model and optim parameters\n",
    "                saved_model = pickle.load(f)\n",
    "                model, optimizer = saved_model\n",
    "\n",
    "        except OSError:\n",
    "            print('Saved file not found. Creating new cold start model.')\n",
    "            model = Crawler_Policy(input_channels=num_frames, num_actions=num_crawler_actions)\n",
    "            optimizer = optim.RMSprop(model.parameters(), lr=lr,\n",
    "                                      weight_decay=0.1)\n",
    "            running_rewards = []\n",
    "            prior_eps = 0\n",
    "        \"\"\"\n",
    "    # Attach agents to their teams\n",
    "    # 4-28-2019 Add roles and types to enable multi-role teams\n",
    "\n",
    "    teams = []\n",
    "    # Team Vikings\n",
    "    teams.append(Team(name=teams_params[0]['name'],color=teams_params[0]['color'], \\\n",
    "                  culture=teams_params[0]['culture'], roles=teams_params[0]['roles'], \\\n",
    "                  agent_policies=[agents[0]], \\\n",
    "                  agent_roles = [agent['role'] for agent in agents_params[0:1]]))\n",
    "    \n",
    "    # 5-30-2019  Strategist accepts directorship of a team\n",
    "    suntzu = Strategist()\n",
    "    suntzu.accept(teams[0])   # Strategist accepts directorship of Team Viking\n",
    "    \n",
    "    env = CrossingEnv(agents=agents_params, teams=teams_params, \\\n",
    "                  map_name=map_name, river_penalty=river_penalty,  \\\n",
    "                  debug_window = False)   \n",
    "    \n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    if cuda:\n",
    "        for i in range(num_learners):    # Learning agents need to utilize GPU\n",
    "            agents[i].cuda()\n",
    "\n",
    "        \n",
    "    for ep in range(max_episodes):\n",
    "    \n",
    "        print('.', end='')  # To show progress\n",
    "    \n",
    "        # Anneal temperature from temp_start to temp_end\n",
    "        for i in range(num_learners):    # For learning agents\n",
    "            agents[i].temperature = max(temp_end, temp_start - (temp_start - temp_end) * (ep / max_episodes))\n",
    "\n",
    "        env_obs = env.reset()  # Env return observations\n",
    "\n",
    "        # For Debug only\n",
    "        # print (len(env_obs))\n",
    "        # print (env_obs[0].shape)\n",
    "    \n",
    "        # Unpack observations into data structure compatible with Crawler_Policy\n",
    "        agents_obs = unpack_env_obs(env_obs)\n",
    "        \n",
    "        # 5-30-2019 Strategist uses the obs space of its team eye as the big picture\n",
    "        game_space = agents_obs[suntzu.eyes[0].idx]\n",
    "        goals, topology = suntzu.generate_goals(game_space)\n",
    "        deltas = calc_norm_deltas(goals[0], env.agent_locations[0])\n",
    "        agents[0].deltas.append(deltas)   # Store a history of deltas for generating mission rewards\n",
    "\n",
    "        for i in range(num_learners):    # Reset agent info - laser tag statistics\n",
    "            agents[i].reset_info()   \n",
    "\n",
    "        # For Debug only\n",
    "        # print (len(agents_obs))\n",
    "        # print (agents_obs[0].shape)\n",
    "    \n",
    "        \"\"\"\n",
    "        For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "        state = np.stack([state]*num_frames)\n",
    "\n",
    "        # LSTM change - reset LSTM hidden units when episode begins\n",
    "        cx = Variable(torch.zeros(1, 256))\n",
    "        hx = Variable(torch.zeros(1, 256))\n",
    "        if cuda:\n",
    "            cx = cx.cuda()\n",
    "            hx = hx.cuda()\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize reward and agents crossed counters\n",
    "        episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "        episode_delta = 0                               # distance from goal for an episode\n",
    "        crossed = [0 for i in range(num_learners)]      # whether an agent has crossed to the 2nd food pile  \n",
    "        episode_crossed = 0                             # num learners who has crossed for an episode\n",
    "    \n",
    "        for frame in range(max_frames):\n",
    "\n",
    "            \"\"\"\n",
    "            For now, we do not implement LSTM\n",
    "            # Select action\n",
    "            # LSTM Change: Need to cycle hx and cx thru select_action\n",
    "            action, log_prob, value, (hx,cx)  = select_action(model, state, (hx,cx), cuda)        \n",
    "            \"\"\"\n",
    "\n",
    "            for i in range(num_learners):    # For learning agents\n",
    "                if agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'leader':\n",
    "                    # 6-02-2019 Simple droneleaders do not require obs space as input\n",
    "                    actions[i], log_probs[i] = select_action_strat_simple(agents[i], deltas, cuda)\n",
    "                else:    \n",
    "                    actions[i], log_probs[i] = select_action(agents[i], agents_obs[i], cuda)\n",
    "                \n",
    "                # Only crawlers can fire lasers\n",
    "                if agents_params[i]['type'] is 'crawler':\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                        \n",
    "                agents[i].saved_actions.append((log_probs[i]))\n",
    "            \n",
    "                # Do not implement LSTM for now\n",
    "                # actions[i].saved_actions.append((log_prob, value))\n",
    "            \n",
    "            for i in range(num_learners, num_learners+num_trained):\n",
    "                print (\"No trained agent exist yet!\")\n",
    "                raise\n",
    "            for i in range(num_learners+num_trained, num_agents):   # For random agents\n",
    "                actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                if actions[i] is 6:\n",
    "                    tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "            # For Debug only\n",
    "            # if frame % 20 == 0:\n",
    "            #    print (actions) \n",
    "            #    print (log_probs)\n",
    "            \n",
    "            # Perform step        \n",
    "            env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "            \"\"\"\n",
    "            For Debug only\n",
    "            print (env_obs)\n",
    "            print (reward)\n",
    "            print (done) \n",
    "            \"\"\"\n",
    "       \n",
    "            # Unpack observations into data structure compatible with Crawler_Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "            \n",
    "            load_info(agents, agents_params, info, narrate=False)   # Load agent info for AI agents\n",
    "            \n",
    "            # 5-30-2019 Strategist uses the obs space of its team eye as the big picture\n",
    "            game_space = agents_obs[suntzu.eyes[0].idx]\n",
    "            goals, topology = suntzu.generate_goals(game_space)\n",
    "            deltas = calc_norm_deltas(goals[0], env.agent_locations[0])\n",
    "            agents[0].deltas.append(deltas)   # Store a history of deltas for generating mission rewards\n",
    "\n",
    "            # For learner agents only, generate reward statistics and reward stack for policy gradient\n",
    "            for i in range(num_learners):\n",
    "                agents[i].rewards.append(reward[i])  # Stack rewards (for policy gradient)\n",
    "                episode_reward[i] += reward[i]   # accumulate episode reward \n",
    "            \n",
    "            \"\"\"\n",
    "            For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "            # Evict oldest diff add new diff to state\n",
    "            next_state = np.stack([next_state]*num_frames)\n",
    "            next_state[1:, :, :] = state[:-1, :, :]\n",
    "            state = next_state\n",
    "            \"\"\"\n",
    "            \n",
    "            if render and (ep % save_interval == 0):   # render 1 episode every save\n",
    "                env.render()\n",
    "                time.sleep(SPEED)  # Change speed of video rendering\n",
    "\n",
    "            if any(done):\n",
    "                print(\"Done after {} frames\".format(frame))\n",
    "                break\n",
    "\n",
    "        # Keep track num of agents who gather from 2nd food pile. Note that env.consumption tracks the \n",
    "        # agent index and location of apple gathered\n",
    "        for (i, loc) in env.consumption:\n",
    "            if loc[0] > second_pile_x:   # If x-cood of gathered apple is beyond a preset value, it is\n",
    "                                         # in the 2nd pile\n",
    "                crossed[i] = 1\n",
    "        episode_crossed = sum(crossed)   # sum up the num agents who crossed to 2nd pile for the episode\n",
    "                \n",
    "        # Update reward and crossed statistics for learners\n",
    "        for i in range(num_learners):\n",
    "            if running_reward[i] is None:\n",
    "                running_reward[i] = episode_reward[i]\n",
    "            running_reward[i] = running_reward[i] * 0.99 + episode_reward[i] * 0.01\n",
    "            running_rewards[i].append(running_reward[i])\n",
    "            \n",
    "        if running_crossed is None:\n",
    "            running_crossed = episode_crossed\n",
    "        running_crossed = running_crossed * 0.99 + episode_crossed * 0.01\n",
    "        running_crossed_hist.append(running_crossed)\n",
    "        \n",
    "        # 6-02-2019 Update distance from goal for droneleader\n",
    "        target_x, target_y = goals[0]\n",
    "        current_x, current_y = env.agent_locations[0]\n",
    "        episode_delta = abs(target_x - current_x) + abs(target_y - current_y)\n",
    "        \n",
    "        if running_delta is None:\n",
    "            running_delta = episode_delta\n",
    "        running_delta = running_delta * 0.99 + episode_delta * 0.01\n",
    "        running_deltas.append(running_delta)\n",
    "        \n",
    "                \n",
    "        # Track Episode #, temp and highest frames/episode\n",
    "        if (ep+prior_eps+1) % log_interval == 0: \n",
    "            verbose_str = '\\nEpisode {} complete'.format(ep+prior_eps+1)\n",
    "            # verbose_str += '\\tTemp = {:.4}'.format(model.temperature)\n",
    "            print(verbose_str)\n",
    "    \n",
    "            # Display rewards and running rewards for learning agents\n",
    "            for i in range(num_learners):\n",
    "                verbose_str = 'Learner:{}'.format(i)\n",
    "                verbose_str += '\\tReward total:{}'.format(episode_reward[i])\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_reward[i])\n",
    "                verbose_str += '\\tNum agents crossed: {}'.format(episode_crossed)\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_crossed)\n",
    "                verbose_str += '\\tDelta total:{}'.format(episode_delta)\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_delta)\n",
    "                print(verbose_str)\n",
    "    \n",
    "        # Update model\n",
    "        total_norms = finish_episode(teams, agents[0:num_learners], optimizers[0:num_learners], gamma, cuda)\n",
    "\n",
    "        if (ep+prior_eps+1) % log_interval == 0:\n",
    "            print('Max Norms = ',[\"%0.2f\" % i for i in total_norms])\n",
    "\n",
    "        if (ep+prior_eps+1) % save_interval == 0: \n",
    "            for i in range(num_learners):\n",
    "                model_dir = 'models/' + experiment + map_name\n",
    "                results_dir = 'results/' + experiment + map_name\n",
    "\n",
    "                model_file = model_dir+'/{}/t{}_rp{}_{}gs/MA{}_{}_ep{}.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames, \\\n",
    "                        i, game, ep+prior_eps+1)\n",
    "                data_file = results_dir+'/{}/t{}_rp{}_{}gs/MA{}_{}.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames, \\\n",
    "                        i, game)\n",
    "\n",
    "                os.makedirs(os.path.dirname(model_file), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(data_file), exist_ok=True)\n",
    "                \n",
    "                with open(model_file, 'wb') as f:\n",
    "                    # Model Save and Load Update: Include both model and optim parameters \n",
    "                    save_model(f, ep, agents[i], optimizers[i])\n",
    "\n",
    "                with open(data_file, 'wb') as f:\n",
    "                    pickle.dump(running_rewards[i], f)    \n",
    "             \n",
    "            crossed_file = results_dir+'/{}/t{}_rp{}_{}gs/Crossed.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames)\n",
    "            os.makedirs(os.path.dirname(crossed_file), exist_ok=True)\n",
    "            with open(crossed_file, 'wb') as f:\n",
    "                    pickle.dump(running_crossed_hist, f)\n",
    "\n",
    "            delta_file = results_dir+'/{}/t{}_rp{}_{}gs/Delta.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames)\n",
    "            os.makedirs(os.path.dirname(delta_file), exist_ok=True)\n",
    "            with open(delta_file, 'wb') as f:\n",
    "                    pickle.dump(running_deltas, f)\n",
    "\n",
    "    end = time.clock()\n",
    "    print('\\nTraining time: {:.2f} min'.format((end-start)/60.0))\n",
    "            \n",
    "    env.close()  # Close the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - DroneLeader_FC64\n",
    "\n",
    "Train DroneLeader_FC64 from 2 start point on the same map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner agent 0\n",
      "Load Drone Leader.\n",
      "....................................................................................................\n",
      "Episode 100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:36\tRunning mean: 32.27\n",
      "Max Norms =  ['22.60']\n",
      "....................................................................................................\n",
      "Episode 200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:19\tRunning mean: 31.22\n",
      "Max Norms =  ['22.50']\n",
      "....................................................................................................\n",
      "Episode 300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:7\tRunning mean: 25.09\n",
      "Max Norms =  ['16.40']\n",
      "....................................................................................................\n",
      "Episode 400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 22.44\n",
      "Max Norms =  ['11.81']\n",
      "....................................................................................................\n",
      "Episode 500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:36\tRunning mean: 24.02\n",
      "Max Norms =  ['17.77']\n",
      "....................................................................................................\n",
      "Episode 600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:28\tRunning mean: 19.73\n",
      "Max Norms =  ['40.95']\n",
      "....................................................................................................\n",
      "Episode 700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:37\tRunning mean: 18.21\n",
      "Max Norms =  ['16.85']\n",
      "....................................................................................................\n",
      "Episode 800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:28\tRunning mean: 18.93\n",
      "Max Norms =  ['34.27']\n",
      "....................................................................................................\n",
      "Episode 900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:53\tRunning mean: 15.51\n",
      "Max Norms =  ['7.78']\n",
      "....................................................................................................\n",
      "Episode 1000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:55\tRunning mean: 25.36\n",
      "Max Norms =  ['6.42']\n",
      "....................................................................................................\n",
      "Episode 1100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:56\tRunning mean: 21.92\n",
      "Max Norms =  ['0.00']\n",
      "....................................................................................................\n",
      "Episode 1200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 23.18\n",
      "Max Norms =  ['24.19']\n",
      "....................................................................................................\n",
      "Episode 1300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 20.58\n",
      "Max Norms =  ['16.17']\n",
      "....................................................................................................\n",
      "Episode 1400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:56\tRunning mean: 24.98\n",
      "Max Norms =  ['0.00']\n",
      "....................................................................................................\n",
      "Episode 1500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 27.42\n",
      "Max Norms =  ['56.91']\n",
      "....................................................................................................\n",
      "Episode 1600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 25.53\n",
      "Max Norms =  ['49.83']\n",
      "....................................................................................................\n",
      "Episode 1700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:5\tRunning mean: 10.75\n",
      "Max Norms =  ['71.76']\n",
      "....................................................................................................\n",
      "Episode 1800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 5.45\n",
      "Max Norms =  ['82.39']\n",
      "....................................................................................................\n",
      "Episode 1900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 2.994\n",
      "Max Norms =  ['41.69']\n",
      "....................................................................................................\n",
      "Episode 2000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 1.988\n",
      "Max Norms =  ['77.19']\n",
      "\n",
      "Training time: 165.23 sec\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import deque\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Initialize environment\n",
    "game = \"Crossing\"\n",
    "num_crawler_actions = 8                     # Crawlers are capable of 8 actions\n",
    "num_drone_actions = 12                      # Drones are capable of 12 actions\n",
    "num_goal_params = 2    # Goal has 2 parameter\n",
    "\n",
    "experiment = '1T-1L/strategist/'    # 1 team of 1 drone leader directed by a strategist\n",
    "\n",
    "# Map and Parameter sets\n",
    "map_name = \"food_d37_river_w1_d25\"  \n",
    "parameters =[ \n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':0.5, \\\n",
    "             'game_steps':300, 'seed': 54}\n",
    "            ]\n",
    "\n",
    "starts = [\n",
    "    (3,9),\n",
    "    (58,18)\n",
    "]\n",
    "\n",
    "temp_end = 1.0   # temp parameter is annealed from the value stored in parameters['temp_start'] to 1.0 \n",
    "\n",
    "# Initialize training parameters\n",
    "warm_start = False\n",
    "num_frames = 7      # environ observation consists of a list of stacked frames per agent\n",
    "max_episodes = 2000\n",
    "\n",
    "render = True    # This turns on rendering every save so that agents' behavior can be observed\n",
    "SPEED = 1/30\n",
    "second_pile_x = 50  # x-coordinate of the 2nd food pile\n",
    "\n",
    "log_interval = 100\n",
    "save_interval = 200\n",
    "\n",
    "# These trainer parameters works for Atari Breakout\n",
    "gamma = 0.99  \n",
    "lr = 1e-2\n",
    "\n",
    "# Initialize agents parameters\n",
    "#   1 agents - 1 learning agents, 0 trained agent, 0 random agent\n",
    "num_learners = 1\n",
    "num_trained = 0\n",
    "num_rdn = 0\n",
    "\n",
    "num_statics = num_trained + num_rdn\n",
    "num_agents = num_learners + num_statics  \n",
    "\n",
    "# The main code starts here!!!\n",
    "\n",
    "for parameter in parameters:   # Go down the list of parameter sets\n",
    "    \n",
    "    start = time.clock()  # time the training\n",
    "    \n",
    "    torch.manual_seed(parameter['seed'])\n",
    "    situation = '2start_droneleaderfc64_seed_'+str(parameter['seed'])\n",
    "    temp_start = parameter['temp_start']\n",
    "    river_penalty = parameter['river_penalty']\n",
    "    max_frames = parameter['game_steps']\n",
    "    \n",
    "    # Set up parameters of agents and teams as inputs into CrossingEnv\n",
    "    teams_params = [\n",
    "        {'name': 'Vikings', 'color': 'deepskyblue', \n",
    "         'culture': {'name':'pacifist_leadfollow','laser_penalty':-1.0,'target_reward':parameter['target_reward']},\n",
    "         'roles': ['leader','follower'],\n",
    "         'target_zone': None, 'banned_zone': None},\n",
    "    ]\n",
    "    agents_params = [\n",
    "        {'id': 0, 'team': 'Vikings', 'color': 'royalblue', 'type': 'drone',    \\\n",
    "         'role': 'leader', 'start': (3,9)},\n",
    "    ]\n",
    "\n",
    "    # Data structure for agents\n",
    "    agents = []\n",
    "    actions = []\n",
    "    log_probs = []\n",
    "    tags = []\n",
    "    rewards = []\n",
    "    deltas = []   # 6-2-2019 delta coordinates\n",
    "    optimizers = []\n",
    "\n",
    "    # Cold start\n",
    "    if warm_start is False:\n",
    "   \n",
    "        # Initialize learner agents, then load static agents (trained followed by random)\n",
    "        for i in range(num_learners):\n",
    "            \n",
    "            print(\"Learner agent {}\".format(i))\n",
    "            \n",
    "            # Initialize agent policy based on type\n",
    "            if agents_params[i]['type'] is 'crawler':\n",
    "                agents.append(Crawler_Policy(num_frames, num_crawler_actions, i))\n",
    "            elif agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'follower':\n",
    "                agents.append(Drone_Policy(num_frames, num_drone_actions, i)) \n",
    "            elif agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'leader':\n",
    "                print(\"Load Drone Leader.\")\n",
    "                agents.append(DroneLeader_FC64(num_goal_params, num_drone_actions, i)) \n",
    "            else:\n",
    "                raise Exception('Unexpected agent type: {}'.format(agents_params[i]['type']))\n",
    "            \n",
    "            optimizers.append(optim.Adam(agents[i].parameters(), lr=lr))\n",
    "        \n",
    "            # set up optimizer - this works for Atari Breakout\n",
    "            # optimizers.append(optim.RMSprop(agents[i].parameters(), lr=lr, weight_decay=0.1)) \n",
    "        \n",
    "        for i in range(num_learners, num_learners+num_trained):\n",
    "            print (\"Learning with trained agents - not implemented yet!\")\n",
    "            raise\n",
    "            \"\"\"\n",
    "            Disable for now! No need to train with trained agents.\n",
    "            agents.append(Crawler_Policy(num_frames, num_crawler_actions, i))\n",
    "            agents[i].load_weights()         # load weight for static agent        \n",
    "            \"\"\"\n",
    "        for i in range(num_learners+num_trained, num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "\n",
    "    \n",
    "        # Initialize all agent data\n",
    "        actions = [0 for i in range(num_agents)]\n",
    "        log_probs = [0 for i in range(num_agents)]\n",
    "        tags = [0 for i in range(num_agents)]\n",
    "        rewards = [0 for i in range(num_agents)]\n",
    "        deltas = [0 for i in range(num_agents)]\n",
    "\n",
    "        # Keep track of rewards learned by learners\n",
    "        episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "        running_reward = [None for i in range(num_learners)]   # running average\n",
    "        running_rewards = [[] for i in range(num_learners)]   # history of running averages\n",
    "        best_reward = [0 for i in range(num_learners)]    # best running average (for storing best_model)\n",
    "        \n",
    "        # 6-2-2019 Keep track of distance from goal achieved by droneleader\n",
    "        episode_delta = 0   # distance from goal for an episode\n",
    "        running_delta = None   # running distance from goal\n",
    "        running_deltas = []    # history of running distance from goal\n",
    "        best_delta = 0    # best running distance from goal (for storing best_model)        \n",
    "        \n",
    "        # Keep track of num learners who has crossed over to the 2nd food pile\n",
    "        crossed = [0 for i in range(num_learners)]      # whether an agent has crossed to the 2nd food pile  \n",
    "        episode_crossed = 0                             # num learners who has crossed for an episode\n",
    "        running_crossed = None         # running average\n",
    "        running_crossed_hist = []   # history of running averages\n",
    "\n",
    "        # This is to support warm start for training\n",
    "        prior_eps = 0\n",
    "\n",
    "    # Warm start\n",
    "    if warm_start:\n",
    "        print (\"Cannot warm start\")\n",
    "        raise\n",
    "    \n",
    "        \"\"\"\n",
    "        # Disable for now!  Need to ensure model can support training on GPU and game playing\n",
    "        # on both CPU and GPU.\n",
    "    \n",
    "        data_file = 'results/{}.p'.format(game)\n",
    "\n",
    "        try:\n",
    "            with open(data_file, 'rb') as f:\n",
    "                running_rewards = pickle.load(f)\n",
    "                running_reward = running_rewards[-1]\n",
    "\n",
    "            prior_eps = len(running_rewards)\n",
    "\n",
    "            model_file = 'saved_models/actor_critic_{}_ep_{}.p'.format(game, prior_eps)\n",
    "            with open(model_file, 'rb') as f:\n",
    "                # Model Save and Load Update: Include both model and optim parameters\n",
    "                saved_model = pickle.load(f)\n",
    "                model, optimizer = saved_model\n",
    "\n",
    "        except OSError:\n",
    "            print('Saved file not found. Creating new cold start model.')\n",
    "            model = Crawler_Policy(input_channels=num_frames, num_actions=num_crawler_actions)\n",
    "            optimizer = optim.RMSprop(model.parameters(), lr=lr,\n",
    "                                      weight_decay=0.1)\n",
    "            running_rewards = []\n",
    "            prior_eps = 0\n",
    "        \"\"\"\n",
    "    # Attach agents to their teams\n",
    "    # 4-28-2019 Add roles and types to enable multi-role teams\n",
    "\n",
    "    teams = []\n",
    "    # Team Vikings\n",
    "    teams.append(Team(name=teams_params[0]['name'],color=teams_params[0]['color'], \\\n",
    "                  culture=teams_params[0]['culture'], roles=teams_params[0]['roles'], \\\n",
    "                  agent_policies=[agents[0]], \\\n",
    "                  agent_roles = [agent['role'] for agent in agents_params[0:1]]))\n",
    "    \n",
    "    # 5-30-2019  Strategist accepts directorship of a team\n",
    "    suntzu = Strategist()\n",
    "    suntzu.accept(teams[0])   # Strategist accepts directorship of Team Viking\n",
    "    \n",
    "    env = CrossingEnv(agents=agents_params, teams=teams_params, \\\n",
    "                  map_name=map_name, river_penalty=river_penalty,  \\\n",
    "                  debug_window = False)   \n",
    "    \n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    if cuda:\n",
    "        for i in range(num_learners):    # Learning agents need to utilize GPU\n",
    "            agents[i].cuda()\n",
    "\n",
    "        \n",
    "    for ep in range(max_episodes):\n",
    "    \n",
    "        print('.', end='')  # To show progress\n",
    "        \n",
    "        start_x, start_y = starts[random.randint(0,len(starts)-1)]  # randomly pick start point\n",
    "        env.spawn_points[0]=(start_x+20, start_y+20)\n",
    "    \n",
    "        # Anneal temperature from temp_start to temp_end\n",
    "        for i in range(num_learners):    # For learning agents\n",
    "            agents[i].temperature = max(temp_end, temp_start - (temp_start - temp_end) * (ep / max_episodes))\n",
    "\n",
    "        env_obs = env.reset()  # Env return observations\n",
    "\n",
    "        # For Debug only\n",
    "        # print (len(env_obs))\n",
    "        # print (env_obs[0].shape)\n",
    "    \n",
    "        # Unpack observations into data structure compatible with Crawler_Policy\n",
    "        agents_obs = unpack_env_obs(env_obs)\n",
    "        \n",
    "        # 5-30-2019 Strategist uses the obs space of its team eye as the big picture\n",
    "        game_space = agents_obs[suntzu.eyes[0].idx]\n",
    "        goals, topology = suntzu.generate_goals(game_space)\n",
    "        deltas = calc_norm_deltas(goals[0], env.agent_locations[0])\n",
    "        agents[0].deltas.append(deltas)   # Store a history of deltas for generating mission rewards\n",
    "\n",
    "        for i in range(num_learners):    # Reset agent info - laser tag statistics\n",
    "            agents[i].reset_info()   \n",
    "\n",
    "        # For Debug only\n",
    "        # print (len(agents_obs))\n",
    "        # print (agents_obs[0].shape)\n",
    "    \n",
    "        \"\"\"\n",
    "        For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "        state = np.stack([state]*num_frames)\n",
    "\n",
    "        # LSTM change - reset LSTM hidden units when episode begins\n",
    "        cx = Variable(torch.zeros(1, 256))\n",
    "        hx = Variable(torch.zeros(1, 256))\n",
    "        if cuda:\n",
    "            cx = cx.cuda()\n",
    "            hx = hx.cuda()\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize reward and agents crossed counters\n",
    "        episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "        episode_delta = 0                               # distance from goal for an episode\n",
    "        crossed = [0 for i in range(num_learners)]      # whether an agent has crossed to the 2nd food pile  \n",
    "        episode_crossed = 0                             # num learners who has crossed for an episode\n",
    "    \n",
    "        for frame in range(max_frames):\n",
    "\n",
    "            \"\"\"\n",
    "            For now, we do not implement LSTM\n",
    "            # Select action\n",
    "            # LSTM Change: Need to cycle hx and cx thru select_action\n",
    "            action, log_prob, value, (hx,cx)  = select_action(model, state, (hx,cx), cuda)        \n",
    "            \"\"\"\n",
    "\n",
    "            for i in range(num_learners):    # For learning agents\n",
    "                if agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'leader':\n",
    "                    # 6-02-2019 Simple droneleaders do not require obs space as input\n",
    "                    actions[i], log_probs[i] = select_action_strat_simple(agents[i], deltas, cuda)\n",
    "                else:    \n",
    "                    actions[i], log_probs[i] = select_action(agents[i], agents_obs[i], cuda)\n",
    "                \n",
    "                # Only crawlers can fire lasers\n",
    "                if agents_params[i]['type'] is 'crawler':\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                        \n",
    "                agents[i].saved_actions.append((log_probs[i]))\n",
    "            \n",
    "                # Do not implement LSTM for now\n",
    "                # actions[i].saved_actions.append((log_prob, value))\n",
    "            \n",
    "            for i in range(num_learners, num_learners+num_trained):\n",
    "                print (\"No trained agent exist yet!\")\n",
    "                raise\n",
    "            for i in range(num_learners+num_trained, num_agents):   # For random agents\n",
    "                actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                if actions[i] is 6:\n",
    "                    tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "            # For Debug only\n",
    "            # if frame % 20 == 0:\n",
    "            #    print (actions) \n",
    "            #    print (log_probs)\n",
    "            \n",
    "            # Perform step        \n",
    "            env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "            \"\"\"\n",
    "            For Debug only\n",
    "            print (env_obs)\n",
    "            print (reward)\n",
    "            print (done) \n",
    "            \"\"\"\n",
    "       \n",
    "            # Unpack observations into data structure compatible with Crawler_Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "            \n",
    "            load_info(agents, agents_params, info, narrate=False)   # Load agent info for AI agents\n",
    "            \n",
    "            # 5-30-2019 Strategist uses the obs space of its team eye as the big picture\n",
    "            game_space = agents_obs[suntzu.eyes[0].idx]\n",
    "            goals, topology = suntzu.generate_goals(game_space)\n",
    "            deltas = calc_norm_deltas(goals[0], env.agent_locations[0])\n",
    "            agents[0].deltas.append(deltas)   # Store a history of deltas for generating mission rewards\n",
    "\n",
    "            # For learner agents only, generate reward statistics and reward stack for policy gradient\n",
    "            for i in range(num_learners):\n",
    "                agents[i].rewards.append(reward[i])  # Stack rewards (for policy gradient)\n",
    "                episode_reward[i] += reward[i]   # accumulate episode reward \n",
    "            \n",
    "            \"\"\"\n",
    "            For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "            # Evict oldest diff add new diff to state\n",
    "            next_state = np.stack([next_state]*num_frames)\n",
    "            next_state[1:, :, :] = state[:-1, :, :]\n",
    "            state = next_state\n",
    "            \"\"\"\n",
    "            \n",
    "            if render and (ep % save_interval == 0):   # render 1 episode every save\n",
    "                env.render()\n",
    "                time.sleep(SPEED)  # Change speed of video rendering\n",
    "\n",
    "            if any(done):\n",
    "                print(\"Done after {} frames\".format(frame))\n",
    "                break\n",
    "\n",
    "        # Keep track num of agents who gather from 2nd food pile. Note that env.consumption tracks the \n",
    "        # agent index and location of apple gathered\n",
    "        for (i, loc) in env.consumption:\n",
    "            if loc[0] > second_pile_x:   # If x-cood of gathered apple is beyond a preset value, it is\n",
    "                                         # in the 2nd pile\n",
    "                crossed[i] = 1\n",
    "        episode_crossed = sum(crossed)   # sum up the num agents who crossed to 2nd pile for the episode\n",
    "                \n",
    "        # Update reward and crossed statistics for learners\n",
    "        for i in range(num_learners):\n",
    "            if running_reward[i] is None:\n",
    "                running_reward[i] = episode_reward[i]\n",
    "            running_reward[i] = running_reward[i] * 0.99 + episode_reward[i] * 0.01\n",
    "            running_rewards[i].append(running_reward[i])\n",
    "            \n",
    "        if running_crossed is None:\n",
    "            running_crossed = episode_crossed\n",
    "        running_crossed = running_crossed * 0.99 + episode_crossed * 0.01\n",
    "        running_crossed_hist.append(running_crossed)\n",
    "        \n",
    "        # 6-02-2019 Update distance from goal for droneleader\n",
    "        target_x, target_y = goals[0]\n",
    "        current_x, current_y = env.agent_locations[0]\n",
    "        episode_delta = abs(target_x - current_x) + abs(target_y - current_y)\n",
    "        \n",
    "        if running_delta is None:\n",
    "            running_delta = episode_delta\n",
    "        running_delta = running_delta * 0.99 + episode_delta * 0.01\n",
    "        running_deltas.append(running_delta)\n",
    "        \n",
    "                \n",
    "        # Track Episode #, temp and highest frames/episode\n",
    "        if (ep+prior_eps+1) % log_interval == 0: \n",
    "            verbose_str = '\\nEpisode {} complete'.format(ep+prior_eps+1)\n",
    "            # verbose_str += '\\tTemp = {:.4}'.format(model.temperature)\n",
    "            print(verbose_str)\n",
    "    \n",
    "            # Display rewards and running rewards for learning agents\n",
    "            for i in range(num_learners):\n",
    "                verbose_str = 'Learner:{}'.format(i)\n",
    "                verbose_str += '\\tReward total:{}'.format(episode_reward[i])\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_reward[i])\n",
    "                verbose_str += '\\tNum agents crossed: {}'.format(episode_crossed)\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_crossed)\n",
    "                verbose_str += '\\tDelta total:{}'.format(episode_delta)\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_delta)\n",
    "                print(verbose_str)\n",
    "    \n",
    "        # Update model\n",
    "        total_norms = finish_episode(teams, agents[0:num_learners], optimizers[0:num_learners], gamma, cuda)\n",
    "\n",
    "        if (ep+prior_eps+1) % log_interval == 0:\n",
    "            print('Max Norms = ',[\"%0.2f\" % i for i in total_norms])\n",
    "\n",
    "        if (ep+prior_eps+1) % save_interval == 0: \n",
    "            for i in range(num_learners):\n",
    "                model_dir = 'models/' + experiment + map_name\n",
    "                results_dir = 'results/' + experiment + map_name\n",
    "\n",
    "                model_file = model_dir+'/{}/t{}_rp{}_{}gs/MA{}_{}_ep{}.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames, \\\n",
    "                        i, game, ep+prior_eps+1)\n",
    "                data_file = results_dir+'/{}/t{}_rp{}_{}gs/MA{}_{}.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames, \\\n",
    "                        i, game)\n",
    "\n",
    "                os.makedirs(os.path.dirname(model_file), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(data_file), exist_ok=True)\n",
    "                \n",
    "                with open(model_file, 'wb') as f:\n",
    "                    # Model Save and Load Update: Include both model and optim parameters \n",
    "                    save_model(f, ep, agents[i], optimizers[i])\n",
    "\n",
    "                with open(data_file, 'wb') as f:\n",
    "                    pickle.dump(running_rewards[i], f)    \n",
    "             \n",
    "            crossed_file = results_dir+'/{}/t{}_rp{}_{}gs/Crossed.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames)\n",
    "            os.makedirs(os.path.dirname(crossed_file), exist_ok=True)\n",
    "            with open(crossed_file, 'wb') as f:\n",
    "                    pickle.dump(running_crossed_hist, f)\n",
    "\n",
    "            delta_file = results_dir+'/{}/t{}_rp{}_{}gs/Delta.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames)\n",
    "            os.makedirs(os.path.dirname(delta_file), exist_ok=True)\n",
    "            with open(delta_file, 'wb') as f:\n",
    "                    pickle.dump(running_deltas, f)\n",
    "\n",
    "    end = time.clock()\n",
    "    print('\\nTraining time: {:.2f} min'.format((end-start)/60.0))\n",
    "            \n",
    "    env.close()  # Close the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DroneLeader_FC64\n",
    "\n",
    "Since the primary skill the drone leader needs is the ability to move in the game space so that delta_x and delta_y both go to zero. We design a new training regimen:\n",
    "\n",
    "(1) Food_center.txt - the food pile is located in the center of the 60x20 game space\n",
    "(2) The agent is started in one of 4 locations at the 4 corners of the game space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner agent 0\n",
      "Load Drone Leader.\n",
      "....................................................................................................\n",
      "Episode 100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:27\tRunning mean: 26.53\n",
      "Max Norms =  ['30.02']\n",
      "....................................................................................................\n",
      "Episode 200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:20\tRunning mean: 26.11\n",
      "Max Norms =  ['23.32']\n",
      "....................................................................................................\n",
      "Episode 300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:6\tRunning mean: 16.57\n",
      "Max Norms =  ['20.61']\n",
      "....................................................................................................\n",
      "Episode 400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 9.01\n",
      "Max Norms =  ['15.26']\n",
      "....................................................................................................\n",
      "Episode 500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 5.776\n",
      "Max Norms =  ['17.47']\n",
      "....................................................................................................\n",
      "Episode 600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 4.205\n",
      "Max Norms =  ['42.62']\n",
      "....................................................................................................\n",
      "Episode 700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:4\tRunning mean: 2.815\n",
      "Max Norms =  ['26.58']\n",
      "....................................................................................................\n",
      "Episode 800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.133\n",
      "Max Norms =  ['19.75']\n",
      "....................................................................................................\n",
      "Episode 900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.017\n",
      "Max Norms =  ['20.63']\n",
      "....................................................................................................\n",
      "Episode 1000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 1.669\n",
      "Max Norms =  ['38.12']\n",
      "....................................................................................................\n",
      "Episode 1100 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:3\tRunning mean: 2.102\n",
      "Max Norms =  ['33.40']\n",
      "....................................................................................................\n",
      "Episode 1200 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 2.686\n",
      "Max Norms =  ['32.38']\n",
      "....................................................................................................\n",
      "Episode 1300 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 1.94\n",
      "Max Norms =  ['54.63']\n",
      "....................................................................................................\n",
      "Episode 1400 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 1.681\n",
      "Max Norms =  ['35.05']\n",
      "....................................................................................................\n",
      "Episode 1500 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 1.451\n",
      "Max Norms =  ['49.89']\n",
      "....................................................................................................\n",
      "Episode 1600 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 1.184\n",
      "Max Norms =  ['21.15']\n",
      "....................................................................................................\n",
      "Episode 1700 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:2\tRunning mean: 1.17\n",
      "Max Norms =  ['65.30']\n",
      "....................................................................................................\n",
      "Episode 1800 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 1.018\n",
      "Max Norms =  ['77.01']\n",
      "....................................................................................................\n",
      "Episode 1900 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:1\tRunning mean: 1.257\n",
      "Max Norms =  ['41.12']\n",
      "....................................................................................................\n",
      "Episode 2000 complete\n",
      "Learner:0\tReward total:0\tRunning mean: 0.0\tNum agents crossed: 0\tRunning mean: 0.0\tDelta total:0\tRunning mean: 1.128\n",
      "Max Norms =  ['32.18']\n",
      "\n",
      "Training time: 166.83 min\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import deque\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Initialize environment\n",
    "game = \"Crossing\"\n",
    "num_crawler_actions = 8                     # Crawlers are capable of 8 actions\n",
    "num_drone_actions = 12                      # Drones are capable of 12 actions\n",
    "num_goal_params = 2    # Goal has 2 parameter\n",
    "\n",
    "experiment = '1T-1L/strategist/'    # 1 team of 1 drone leader directed by a strategist\n",
    "\n",
    "# Map and Parameter sets\n",
    "map_name = \"food_center\"  \n",
    "parameters =[ \n",
    "            {'temp_start':2.0, 'river_penalty':-1.0, 'target_reward':0.5, \\\n",
    "             'game_steps':300, 'seed': 54}\n",
    "            ]\n",
    "\n",
    "starts = [\n",
    "    (3,9),\n",
    "    (3,18),\n",
    "    (57,9),\n",
    "    (57,18),\n",
    "]\n",
    "\n",
    "temp_end = 1.0   # temp parameter is annealed from the value stored in parameters['temp_start'] to 1.0 \n",
    "\n",
    "# Initialize training parameters\n",
    "warm_start = False\n",
    "num_frames = 7      # environ observation consists of a list of stacked frames per agent\n",
    "max_episodes = 2000\n",
    "\n",
    "render = True    # This turns on rendering every save so that agents' behavior can be observed\n",
    "SPEED = 1/30\n",
    "second_pile_x = 50  # x-coordinate of the 2nd food pile\n",
    "\n",
    "log_interval = 100\n",
    "save_interval = 200\n",
    "\n",
    "# These trainer parameters works for Atari Breakout\n",
    "gamma = 0.99  \n",
    "lr = 1e-2\n",
    "\n",
    "# Initialize agents parameters\n",
    "#   1 agents - 1 learning agents, 0 trained agent, 0 random agent\n",
    "num_learners = 1\n",
    "num_trained = 0\n",
    "num_rdn = 0\n",
    "\n",
    "num_statics = num_trained + num_rdn\n",
    "num_agents = num_learners + num_statics  \n",
    "\n",
    "# The main code starts here!!!\n",
    "\n",
    "for parameter in parameters:   # Go down the list of parameter sets\n",
    "    \n",
    "    start = time.clock()  # time the training\n",
    "    \n",
    "    torch.manual_seed(parameter['seed'])\n",
    "    situation = '2start_droneleaderfc64_seed_'+str(parameter['seed'])\n",
    "    temp_start = parameter['temp_start']\n",
    "    river_penalty = parameter['river_penalty']\n",
    "    max_frames = parameter['game_steps']\n",
    "    \n",
    "    # Set up parameters of agents and teams as inputs into CrossingEnv\n",
    "    teams_params = [\n",
    "        {'name': 'Vikings', 'color': 'deepskyblue', \n",
    "         'culture': {'name':'pacifist_leadfollow','laser_penalty':-1.0,'target_reward':parameter['target_reward']},\n",
    "         'roles': ['leader','follower'],\n",
    "         'target_zone': None, 'banned_zone': None},\n",
    "    ]\n",
    "    agents_params = [\n",
    "        {'id': 0, 'team': 'Vikings', 'color': 'royalblue', 'type': 'drone',    \\\n",
    "         'role': 'leader', 'start': (3,9)},\n",
    "    ]\n",
    "\n",
    "    # Data structure for agents\n",
    "    agents = []\n",
    "    actions = []\n",
    "    log_probs = []\n",
    "    tags = []\n",
    "    rewards = []\n",
    "    deltas = []   # 6-2-2019 delta coordinates\n",
    "    optimizers = []\n",
    "\n",
    "    # Cold start\n",
    "    if warm_start is False:\n",
    "   \n",
    "        # Initialize learner agents, then load static agents (trained followed by random)\n",
    "        for i in range(num_learners):\n",
    "            \n",
    "            print(\"Learner agent {}\".format(i))\n",
    "            \n",
    "            # Initialize agent policy based on type\n",
    "            if agents_params[i]['type'] is 'crawler':\n",
    "                agents.append(Crawler_Policy(num_frames, num_crawler_actions, i))\n",
    "            elif agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'follower':\n",
    "                agents.append(Drone_Policy(num_frames, num_drone_actions, i)) \n",
    "            elif agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'leader':\n",
    "                print(\"Load Drone Leader.\")\n",
    "                agents.append(DroneLeader_FC64(num_goal_params, num_drone_actions, i)) \n",
    "            else:\n",
    "                raise Exception('Unexpected agent type: {}'.format(agents_params[i]['type']))\n",
    "            \n",
    "            optimizers.append(optim.Adam(agents[i].parameters(), lr=lr))\n",
    "        \n",
    "            # set up optimizer - this works for Atari Breakout\n",
    "            # optimizers.append(optim.RMSprop(agents[i].parameters(), lr=lr, weight_decay=0.1)) \n",
    "        \n",
    "        for i in range(num_learners, num_learners+num_trained):\n",
    "            print (\"Learning with trained agents - not implemented yet!\")\n",
    "            raise\n",
    "            \"\"\"\n",
    "            Disable for now! No need to train with trained agents.\n",
    "            agents.append(Crawler_Policy(num_frames, num_crawler_actions, i))\n",
    "            agents[i].load_weights()         # load weight for static agent        \n",
    "            \"\"\"\n",
    "        for i in range(num_learners+num_trained, num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "\n",
    "    \n",
    "        # Initialize all agent data\n",
    "        actions = [0 for i in range(num_agents)]\n",
    "        log_probs = [0 for i in range(num_agents)]\n",
    "        tags = [0 for i in range(num_agents)]\n",
    "        rewards = [0 for i in range(num_agents)]\n",
    "        deltas = [0 for i in range(num_agents)]\n",
    "\n",
    "        # Keep track of rewards learned by learners\n",
    "        episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "        running_reward = [None for i in range(num_learners)]   # running average\n",
    "        running_rewards = [[] for i in range(num_learners)]   # history of running averages\n",
    "        best_reward = [0 for i in range(num_learners)]    # best running average (for storing best_model)\n",
    "        \n",
    "        # 6-2-2019 Keep track of distance from goal achieved by droneleader\n",
    "        episode_delta = 0   # distance from goal for an episode\n",
    "        running_delta = None   # running distance from goal\n",
    "        running_deltas = []    # history of running distance from goal\n",
    "        best_delta = 0    # best running distance from goal (for storing best_model)        \n",
    "        \n",
    "        # Keep track of num learners who has crossed over to the 2nd food pile\n",
    "        crossed = [0 for i in range(num_learners)]      # whether an agent has crossed to the 2nd food pile  \n",
    "        episode_crossed = 0                             # num learners who has crossed for an episode\n",
    "        running_crossed = None         # running average\n",
    "        running_crossed_hist = []   # history of running averages\n",
    "\n",
    "        # This is to support warm start for training\n",
    "        prior_eps = 0\n",
    "\n",
    "    # Warm start\n",
    "    if warm_start:\n",
    "        print (\"Cannot warm start\")\n",
    "        raise\n",
    "    \n",
    "        \"\"\"\n",
    "        # Disable for now!  Need to ensure model can support training on GPU and game playing\n",
    "        # on both CPU and GPU.\n",
    "    \n",
    "        data_file = 'results/{}.p'.format(game)\n",
    "\n",
    "        try:\n",
    "            with open(data_file, 'rb') as f:\n",
    "                running_rewards = pickle.load(f)\n",
    "                running_reward = running_rewards[-1]\n",
    "\n",
    "            prior_eps = len(running_rewards)\n",
    "\n",
    "            model_file = 'saved_models/actor_critic_{}_ep_{}.p'.format(game, prior_eps)\n",
    "            with open(model_file, 'rb') as f:\n",
    "                # Model Save and Load Update: Include both model and optim parameters\n",
    "                saved_model = pickle.load(f)\n",
    "                model, optimizer = saved_model\n",
    "\n",
    "        except OSError:\n",
    "            print('Saved file not found. Creating new cold start model.')\n",
    "            model = Crawler_Policy(input_channels=num_frames, num_actions=num_crawler_actions)\n",
    "            optimizer = optim.RMSprop(model.parameters(), lr=lr,\n",
    "                                      weight_decay=0.1)\n",
    "            running_rewards = []\n",
    "            prior_eps = 0\n",
    "        \"\"\"\n",
    "    # Attach agents to their teams\n",
    "    # 4-28-2019 Add roles and types to enable multi-role teams\n",
    "\n",
    "    teams = []\n",
    "    # Team Vikings\n",
    "    teams.append(Team(name=teams_params[0]['name'],color=teams_params[0]['color'], \\\n",
    "                  culture=teams_params[0]['culture'], roles=teams_params[0]['roles'], \\\n",
    "                  agent_policies=[agents[0]], \\\n",
    "                  agent_roles = [agent['role'] for agent in agents_params[0:1]]))\n",
    "    \n",
    "    # 5-30-2019  Strategist accepts directorship of a team\n",
    "    suntzu = Strategist()\n",
    "    suntzu.accept(teams[0])   # Strategist accepts directorship of Team Viking\n",
    "    \n",
    "    env = CrossingEnv(agents=agents_params, teams=teams_params, \\\n",
    "                  map_name=map_name, river_penalty=river_penalty,  \\\n",
    "                  debug_window = False)   \n",
    "    \n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    if cuda:\n",
    "        for i in range(num_learners):    # Learning agents need to utilize GPU\n",
    "            agents[i].cuda()\n",
    "\n",
    "        \n",
    "    for ep in range(max_episodes):\n",
    "    \n",
    "        print('.', end='')  # To show progress\n",
    "        \n",
    "        start_x, start_y = starts[random.randint(0,len(starts)-1)]  # randomly pick start point\n",
    "        env.spawn_points[0]=(start_x+20, start_y+20)\n",
    "    \n",
    "        # Anneal temperature from temp_start to temp_end\n",
    "        for i in range(num_learners):    # For learning agents\n",
    "            agents[i].temperature = max(temp_end, temp_start - (temp_start - temp_end) * (ep / max_episodes))\n",
    "\n",
    "        env_obs = env.reset()  # Env return observations\n",
    "\n",
    "        # For Debug only\n",
    "        # print (len(env_obs))\n",
    "        # print (env_obs[0].shape)\n",
    "    \n",
    "        # Unpack observations into data structure compatible with Crawler_Policy\n",
    "        agents_obs = unpack_env_obs(env_obs)\n",
    "        \n",
    "        # 5-30-2019 Strategist uses the obs space of its team eye as the big picture\n",
    "        game_space = agents_obs[suntzu.eyes[0].idx]\n",
    "        goals, topology = suntzu.generate_goals(game_space)\n",
    "        deltas = calc_norm_deltas(goals[0], env.agent_locations[0])\n",
    "        agents[0].deltas.append(deltas)   # Store a history of deltas for generating mission rewards\n",
    "\n",
    "        for i in range(num_learners):    # Reset agent info - laser tag statistics\n",
    "            agents[i].reset_info()   \n",
    "\n",
    "        # For Debug only\n",
    "        # print (len(agents_obs))\n",
    "        # print (agents_obs[0].shape)\n",
    "    \n",
    "        \"\"\"\n",
    "        For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "        state = np.stack([state]*num_frames)\n",
    "\n",
    "        # LSTM change - reset LSTM hidden units when episode begins\n",
    "        cx = Variable(torch.zeros(1, 256))\n",
    "        hx = Variable(torch.zeros(1, 256))\n",
    "        if cuda:\n",
    "            cx = cx.cuda()\n",
    "            hx = hx.cuda()\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize reward and agents crossed counters\n",
    "        episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "        episode_delta = 0                               # distance from goal for an episode\n",
    "        crossed = [0 for i in range(num_learners)]      # whether an agent has crossed to the 2nd food pile  \n",
    "        episode_crossed = 0                             # num learners who has crossed for an episode\n",
    "    \n",
    "        for frame in range(max_frames):\n",
    "\n",
    "            \"\"\"\n",
    "            For now, we do not implement LSTM\n",
    "            # Select action\n",
    "            # LSTM Change: Need to cycle hx and cx thru select_action\n",
    "            action, log_prob, value, (hx,cx)  = select_action(model, state, (hx,cx), cuda)        \n",
    "            \"\"\"\n",
    "\n",
    "            for i in range(num_learners):    # For learning agents\n",
    "                if agents_params[i]['type'] is 'drone' and agents_params[i]['role'] is 'leader':\n",
    "                    # 6-02-2019 Simple droneleaders do not require obs space as input\n",
    "                    actions[i], log_probs[i] = select_action_strat_simple(agents[i], deltas, cuda)\n",
    "                else:    \n",
    "                    actions[i], log_probs[i] = select_action(agents[i], agents_obs[i], cuda)\n",
    "                \n",
    "                # Only crawlers can fire lasers\n",
    "                if agents_params[i]['type'] is 'crawler':\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                        \n",
    "                agents[i].saved_actions.append((log_probs[i]))\n",
    "            \n",
    "                # Do not implement LSTM for now\n",
    "                # actions[i].saved_actions.append((log_prob, value))\n",
    "            \n",
    "            for i in range(num_learners, num_learners+num_trained):\n",
    "                print (\"No trained agent exist yet!\")\n",
    "                raise\n",
    "            for i in range(num_learners+num_trained, num_agents):   # For random agents\n",
    "                actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                if actions[i] is 6:\n",
    "                    tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "            # For Debug only\n",
    "            # if frame % 20 == 0:\n",
    "            #    print (actions) \n",
    "            #    print (log_probs)\n",
    "            \n",
    "            # Perform step        \n",
    "            env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "            \"\"\"\n",
    "            For Debug only\n",
    "            print (env_obs)\n",
    "            print (reward)\n",
    "            print (done) \n",
    "            \"\"\"\n",
    "       \n",
    "            # Unpack observations into data structure compatible with Crawler_Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "            \n",
    "            load_info(agents, agents_params, info, narrate=False)   # Load agent info for AI agents\n",
    "            \n",
    "            # 5-30-2019 Strategist uses the obs space of its team eye as the big picture\n",
    "            game_space = agents_obs[suntzu.eyes[0].idx]\n",
    "            goals, topology = suntzu.generate_goals(game_space)\n",
    "            deltas = calc_norm_deltas(goals[0], env.agent_locations[0])\n",
    "            agents[0].deltas.append(deltas)   # Store a history of deltas for generating mission rewards\n",
    "\n",
    "            # For learner agents only, generate reward statistics and reward stack for policy gradient\n",
    "            for i in range(num_learners):\n",
    "                agents[i].rewards.append(reward[i])  # Stack rewards (for policy gradient)\n",
    "                episode_reward[i] += reward[i]   # accumulate episode reward \n",
    "            \n",
    "            \"\"\"\n",
    "            For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "            # Evict oldest diff add new diff to state\n",
    "            next_state = np.stack([next_state]*num_frames)\n",
    "            next_state[1:, :, :] = state[:-1, :, :]\n",
    "            state = next_state\n",
    "            \"\"\"\n",
    "            \n",
    "            if render and (ep % save_interval == 0):   # render 1 episode every save\n",
    "                env.render()\n",
    "                time.sleep(SPEED)  # Change speed of video rendering\n",
    "\n",
    "            if any(done):\n",
    "                print(\"Done after {} frames\".format(frame))\n",
    "                break\n",
    "\n",
    "        # Keep track num of agents who gather from 2nd food pile. Note that env.consumption tracks the \n",
    "        # agent index and location of apple gathered\n",
    "        for (i, loc) in env.consumption:\n",
    "            if loc[0] > second_pile_x:   # If x-cood of gathered apple is beyond a preset value, it is\n",
    "                                         # in the 2nd pile\n",
    "                crossed[i] = 1\n",
    "        episode_crossed = sum(crossed)   # sum up the num agents who crossed to 2nd pile for the episode\n",
    "                \n",
    "        # Update reward and crossed statistics for learners\n",
    "        for i in range(num_learners):\n",
    "            if running_reward[i] is None:\n",
    "                running_reward[i] = episode_reward[i]\n",
    "            running_reward[i] = running_reward[i] * 0.99 + episode_reward[i] * 0.01\n",
    "            running_rewards[i].append(running_reward[i])\n",
    "            \n",
    "        if running_crossed is None:\n",
    "            running_crossed = episode_crossed\n",
    "        running_crossed = running_crossed * 0.99 + episode_crossed * 0.01\n",
    "        running_crossed_hist.append(running_crossed)\n",
    "        \n",
    "        # 6-02-2019 Update distance from goal for droneleader\n",
    "        target_x, target_y = goals[0]\n",
    "        current_x, current_y = env.agent_locations[0]\n",
    "        episode_delta = abs(target_x - current_x) + abs(target_y - current_y)\n",
    "        \n",
    "        if running_delta is None:\n",
    "            running_delta = episode_delta\n",
    "        running_delta = running_delta * 0.99 + episode_delta * 0.01\n",
    "        running_deltas.append(running_delta)\n",
    "        \n",
    "                \n",
    "        # Track Episode #, temp and highest frames/episode\n",
    "        if (ep+prior_eps+1) % log_interval == 0: \n",
    "            verbose_str = '\\nEpisode {} complete'.format(ep+prior_eps+1)\n",
    "            # verbose_str += '\\tTemp = {:.4}'.format(model.temperature)\n",
    "            print(verbose_str)\n",
    "    \n",
    "            # Display rewards and running rewards for learning agents\n",
    "            for i in range(num_learners):\n",
    "                verbose_str = 'Learner:{}'.format(i)\n",
    "                verbose_str += '\\tReward total:{}'.format(episode_reward[i])\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_reward[i])\n",
    "                verbose_str += '\\tNum agents crossed: {}'.format(episode_crossed)\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_crossed)\n",
    "                verbose_str += '\\tDelta total:{}'.format(episode_delta)\n",
    "                verbose_str += '\\tRunning mean: {:.4}'.format(running_delta)\n",
    "                print(verbose_str)\n",
    "    \n",
    "        # Update model\n",
    "        total_norms = finish_episode(teams, agents[0:num_learners], optimizers[0:num_learners], gamma, cuda)\n",
    "\n",
    "        if (ep+prior_eps+1) % log_interval == 0:\n",
    "            print('Max Norms = ',[\"%0.2f\" % i for i in total_norms])\n",
    "\n",
    "        if (ep+prior_eps+1) % save_interval == 0: \n",
    "            for i in range(num_learners):\n",
    "                model_dir = 'models/' + experiment + map_name\n",
    "                results_dir = 'results/' + experiment + map_name\n",
    "\n",
    "                model_file = model_dir+'/{}/t{}_rp{}_{}gs/MA{}_{}_ep{}.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames, \\\n",
    "                        i, game, ep+prior_eps+1)\n",
    "                data_file = results_dir+'/{}/t{}_rp{}_{}gs/MA{}_{}.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames, \\\n",
    "                        i, game)\n",
    "\n",
    "                os.makedirs(os.path.dirname(model_file), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(data_file), exist_ok=True)\n",
    "                \n",
    "                with open(model_file, 'wb') as f:\n",
    "                    # Model Save and Load Update: Include both model and optim parameters \n",
    "                    save_model(f, ep, agents[i], optimizers[i])\n",
    "\n",
    "                with open(data_file, 'wb') as f:\n",
    "                    pickle.dump(running_rewards[i], f)    \n",
    "             \n",
    "            crossed_file = results_dir+'/{}/t{}_rp{}_{}gs/Crossed.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames)\n",
    "            os.makedirs(os.path.dirname(crossed_file), exist_ok=True)\n",
    "            with open(crossed_file, 'wb') as f:\n",
    "                    pickle.dump(running_crossed_hist, f)\n",
    "\n",
    "            delta_file = results_dir+'/{}/t{}_rp{}_{}gs/Delta.p'.format(situation, \\\n",
    "                        temp_start, river_penalty, max_frames)\n",
    "            os.makedirs(os.path.dirname(delta_file), exist_ok=True)\n",
    "            with open(delta_file, 'wb') as f:\n",
    "                    pickle.dump(running_deltas, f)\n",
    "\n",
    "    end = time.clock()\n",
    "    print('\\nTraining time: {:.2f} min'.format((end-start)/60.0))\n",
    "            \n",
    "    env.close()  # Close the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC32 vs FC64\n",
    "\n",
    "A bigger NN learns better than a smaller NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc32_seed_0/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc32_seed_7/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc32_seed_54/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_0/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_7/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_54/t2.0_rp-1.0_300gs/\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbba9b14080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbba9d20cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbba9aa3668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game = 'Crossing'\n",
    "\n",
    "############# 1T1L Strategist + Simple DroneLeader #############\n",
    "dir_names = [\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc32_seed_0/t2.0_rp-1.0_300gs/\",   # scenario=36\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc32_seed_7/t2.0_rp-1.0_300gs/\",   # scenario=37\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc32_seed_54/t2.0_rp-1.0_300gs/\",  # scenario=38\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_0/t2.0_rp-1.0_300gs/\",   # scenario=39\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_7/t2.0_rp-1.0_300gs/\",   # scenario=40\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_54/t2.0_rp-1.0_300gs/\"   # scenario=41\n",
    "]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, dir_name in enumerate(dir_names):\n",
    "    print (dir_name)\n",
    "   \n",
    "    delta_file = dir_name+'Delta.p'.format(i, game)\n",
    "    with open(delta_file, 'rb') as f:\n",
    "        data.append(pickle.load(f))\n",
    "            \n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(data[0], label='FC32', color='red')\n",
    "plt.plot(data[3], label='FC64', color='blue')\n",
    "\n",
    "plt.title('DroneLeader - Distance to Goal')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(data[1], label='FC32', color='red')\n",
    "plt.plot(data[4], label='FC64', color='blue')\n",
    "\n",
    "plt.title('DroneLeader - Distance to Goal')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(data[2], label='FC32', color='red')\n",
    "plt.plot(data[5], label='FC64', color='blue')\n",
    "\n",
    "plt.title('DroneLeader - Distance to Goal')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Reward\n",
    "\n",
    "We increase the reward of the drone leader staying at the target coordinate from 1.0 to 3.0, and it results in no change at all to the learning trajectories.\n",
    "\n",
    "This is counter-intuitive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_0/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist_step_reward/food_d37_river_w1_d25/droneleaderfc64_seed_0/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_7/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist_step_reward/food_d37_river_w1_d25/droneleaderfc64_seed_7/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist_big_reward/food_d37_river_w1_d25/droneleaderfc64_seed_7/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_54/t2.0_rp-1.0_300gs/\n",
      "results/1T-1L/strategist_step_reward/food_d37_river_w1_d25/droneleaderfc64_seed_54/t2.0_rp-1.0_300gs/\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0f100a7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game = 'Crossing'\n",
    "\n",
    "############# 1T1L Strategist + Simple DroneLeader #############\n",
    "dir_names = [\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_0/t2.0_rp-1.0_300gs/\",   # scenario=36\n",
    "    \"results/1T-1L/strategist_step_reward/food_d37_river_w1_d25/droneleaderfc64_seed_0/t2.0_rp-1.0_300gs/\",   # scenario=37\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_7/t2.0_rp-1.0_300gs/\",\n",
    "    \"results/1T-1L/strategist_step_reward/food_d37_river_w1_d25/droneleaderfc64_seed_7/t2.0_rp-1.0_300gs/\",   # scenario=37\n",
    "    \"results/1T-1L/strategist_big_reward/food_d37_river_w1_d25/droneleaderfc64_seed_7/t2.0_rp-1.0_300gs/\",   # scenario=37\n",
    "    \"results/1T-1L/strategist/food_d37_river_w1_d25/droneleaderfc64_seed_54/t2.0_rp-1.0_300gs/\",\n",
    "    \"results/1T-1L/strategist_step_reward/food_d37_river_w1_d25/droneleaderfc64_seed_54/t2.0_rp-1.0_300gs/\",   # scenario=37\n",
    "]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, dir_name in enumerate(dir_names):\n",
    "    print (dir_name)\n",
    "   \n",
    "    delta_file = dir_name+'Delta.p'.format(i, game)\n",
    "    with open(delta_file, 'rb') as f:\n",
    "        data.append(pickle.load(f))\n",
    "            \n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "\n",
    "plt.plot(data[6], label='step reward', color='red')\n",
    "plt.plot(data[4], label='step reward', color='blue')\n",
    "\n",
    "plt.title('DroneLeader - Distance to Goal')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
